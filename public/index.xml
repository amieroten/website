<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amie Roten</title>
    <link>https://vigilant-golick-64a677.netlify.app/</link>
      <atom:link href="https://vigilant-golick-64a677.netlify.app/index.xml" rel="self" type="application/rss+xml" />
    <description>Amie Roten</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 08 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://vigilant-golick-64a677.netlify.app/images/icon_hu346136ade45dcbd12e910f9894b3a60b_235897_512x512_fill_lanczos_center_2.png</url>
      <title>Amie Roten</title>
      <link>https://vigilant-golick-64a677.netlify.app/</link>
    </image>
    
    <item>
      <title>Comprehensive Exploratory Data Analysis using Shiny!</title>
      <link>https://vigilant-golick-64a677.netlify.app/post/final-viz/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/post/final-viz/</guid>
      <description>


&lt;iframe src=&#34;https://amie-roten.shinyapps.io/Data_Exploration_Phonological_Features/&#34; width=&#34;1056&#34; height=&#34;800px&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;A preliminary note: If the visualization above does not render well on your machine, please visit the application directly, at &lt;a href=&#34;https://amie-roten.shinyapps.io/Data_Exploration_Phonological_Features/&#34; class=&#34;uri&#34;&gt;https://amie-roten.shinyapps.io/Data_Exploration_Phonological_Features/&lt;/a&gt; !&lt;/p&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;The interactive visualization above was created primarily as a final project submission for OHSU’s Data Visualization course, but also as a tool to guide investigation of data from a research project I’ve been working on during my time at OHSU. So, in that sense, this is a bit of a version 1.0, and I plan to keep modifying and updating it as different analyses are required, or certain analyses are found to be more or less usful than others! In addition to building the visualization for these purposes, I also wanted an excuse to play around more with R’s Shiny package, as I think it’s a very cool tool for building interesting, dynamic visualizations!&lt;/p&gt;
&lt;p&gt;For a brief overview, please to check out a short presentation about the visualization below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vimeo.com/428874346&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you’d like more specific, in-depth details, including how I went about building this visualization, read on!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;As mentioned, the data used to build this visualization comes from a research project I’ve been a part of for the last academic year, in which we’ve built a prototype automatic pronunciation assessment system designed for children with speech sound disorders. The system takes in speech as an audio signal, maps each individual frame to a phoneme (aka speech sound, such as ‘sh’/ʃ) as well as a set of phonological features, for example, “voiced”, “coronal”, etc. Then, the mapped phonological features are passed through an additional model, which predicts whether the uttered phoneme from which the feature predictions came was correctly or incorrectly pronounced. In addition to the binary pronunciation judgement, the model also predicts the most-likely phonological feature error contributing to a phoneme being deemed mispronounced, to ultimately be used as corrective feedback for the user of the system, e.g. “this phoneme was unvoiced!”.&lt;/p&gt;
&lt;p&gt;Additionally, for both overall mispronounciation detection and feedback, the user can select a threshold used to determine whether to pass judgement on a particular phoneme. That is, while the system can provide a binary judgement in the form of a zero (mispronounced) or one (correctly pronounced) on whether the phoneme was mispronounced for all input, the raw data output by the model is in the form of a probability of whether the phoneme was correctly pronounced, which we refer to as a “confidence level”. The higher the threshold chosen, the more selective we can be about which phonemes we deliver feedback on. For example, the system may report a phoneme as mispronounced, but if it is only 20% confident, we may not want to deliver feedback to the user, as users can be discouraged and confused if they are told that they have mispronounced a sound when they have not. The confidence level for the feedback assigned can also be adjusted.&lt;/p&gt;
&lt;p&gt;As you can tell, this model generates &lt;em&gt;quite&lt;/em&gt; a lot of data during various phases, and metrics to evaluate the performance of the model, such as accuracy, can differ based on how the data is thresholded. In addition, we evaluated the model using both typically-developing (TD) and speech-disordered (SD) children’s speech, so it would be handy to be able to quickly take a look at how the model performance may differ depending on group. Finally, we assessed the model’s performance using data that has been manually segmented into phonemes, as well as data that was force-aligned. We expect that performance would differ based on the segmentation method as well.&lt;/p&gt;
&lt;p&gt;With all of these ways to drill down into the data, I wanted to create a dashboard where the user could ask a question about the dataset, quickly select the subset of interest, and get a report of the model’s performance for that particular subset. After learning about R’s Shiny library in OHSU’s Data Visualization class, I figured this would be an excellent tool for creating a dashboard to explore this dataset! Spoiler alert – it is!&lt;/p&gt;
&lt;p&gt;I’ve included a glimpse of the dataframe generated by the model below, demonstrating just how much information we were dealing with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read_csv(&amp;quot;data/phono_data_FA.csv&amp;quot;) %&amp;gt;%
        mutate(X1 = NULL)
glimpse(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 17,099
## Columns: 11
## $ actual_phn                   &amp;lt;chr&amp;gt; &amp;quot;d&amp;quot;, &amp;quot;ʌ&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;-&amp;quot;, &amp;quot;æ&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;sʲ&amp;quot;,…
## $ expected_phn                 &amp;lt;chr&amp;gt; &amp;quot;d&amp;quot;, &amp;quot;ʌ&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;w&amp;quot;, &amp;quot;æ&amp;quot;, &amp;quot;k&amp;quot;, &amp;quot;s&amp;quot;, …
## $ actual_score                 &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0…
## $ predicted_score              &amp;lt;dbl&amp;gt; 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1…
## $ predicted_score_conf         &amp;lt;dbl&amp;gt; 0.06636703, 0.33367300, 0.33663034, 0.29…
## $ actual_top_error             &amp;lt;chr&amp;gt; &amp;quot;delrel&amp;quot;, &amp;quot;back&amp;quot;, &amp;quot;cor&amp;quot;, &amp;quot;cor&amp;quot;, &amp;quot;round&amp;quot;,…
## $ predicted_top_error          &amp;lt;chr&amp;gt; &amp;quot;delrel&amp;quot;, &amp;quot;back&amp;quot;, &amp;quot;pause&amp;quot;, &amp;quot;delrel&amp;quot;, &amp;quot;ro…
## $ predicted_top_error_conf     &amp;lt;dbl&amp;gt; 0.9450728, 0.7203612, 0.2179701, 0.19645…
## $ predicted_top_error_validity &amp;lt;lgl&amp;gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE,…
## $ word                         &amp;lt;chr&amp;gt; &amp;quot;duck&amp;quot;, &amp;quot;duck&amp;quot;, &amp;quot;duck&amp;quot;, &amp;quot;quack&amp;quot;, &amp;quot;quack&amp;quot;…
## $ dx                           &amp;lt;chr&amp;gt; &amp;quot;SD&amp;quot;, &amp;quot;SD&amp;quot;, &amp;quot;SD&amp;quot;, &amp;quot;SD&amp;quot;, &amp;quot;SD&amp;quot;, &amp;quot;SD&amp;quot;, &amp;quot;SD&amp;quot;…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, each row corresponds to an actual, uttered phoneme, and includes attributes such as what phoneme was expected to be produced, what the human-assigned score was, what the machine predicted score was, and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;audience&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Audience&lt;/h2&gt;
&lt;p&gt;My goal was to create a way for a user to dig deeper into this dataset than what a single, static visualization could allow. At this point, the model is still in prototype mode, and there are many questions to be answered and knobs to tweak before unleashing this system on the world. So, I designed the dashboard specifically with members of the lab in mind, as well as potentially outside researchers who have dealt with this type of system and data before. Admittedly, this is a visualization with a lot more information on it than most not associated with this project would need, or even want. However, given the stage of the project, including as much information as possible was my goal, in order to uncover any potential problems or nuances of the system to continue to tweak during development.&lt;/p&gt;
&lt;p&gt;I would like to rethink the visualization at some point to be more digestable for a general audience, as I’m pretty proud of this project and would love to share it with a wider set of people. However, at this point, a highly-detailed dashboard with as much information as possible (while still being as aesthetically-pleasing and non-chaotic as could be) was my goal!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;type&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Type&lt;/h2&gt;
&lt;p&gt;As far as categorizing this visualization, it’s a bit difficult to narrow it down to one, particular type of graph/chart. If forced, I’d say it’s a “data dashboard”, of the like often seen these days to share information about the ongoing pandemic, or which might be used by a company to monitor various aspects of their business. These are often created so that a user can explore a large dataset, or multiple datasets, and find specific answers to targeted questions.&lt;/p&gt;
&lt;p&gt;The overall dashboard contains a number of different types of visualizations, including confusion matrices, tables, and a bar chart. I aimed to keep the individual visualizations simple and straightforward to take in, considering there are multiple on the same page. While tables and bar charts are relatively common, straightforward methods of plotting data, confusion matrices may be a bit less well-known. While these visualizations are used in a number of research/academic settings, they are perhaps most often used to describe the performance of a classification algorithm, as in the case of this visualization. Although we can describe performance of a system in terms of overall accuracy, a confusion matrix allows the reader to assess system performance for each particular group/class. For example, we may want to know how well this system accurately identifies incorrectly pronounced phonemes, or how often phonemes pronounced correctly are falsely labeled incorrect. A confusion matrix helps answer these questions in a (more-or-less) straight-forward manner by plotting each possible ground-truth and predicted label combination, and giving the counts for each combination. The left-upper to right-lower diagonal indicates correct predictions, and the other boxes are incorrect predictions. Although it may take some practice to get familar with these visualizations, they’re very handy for fine-grained assessments of a classifier’s performance!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;readers-guide&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reader’s Guide&lt;/h2&gt;
&lt;p&gt;If you’ve made it this far, I’ll assume that you’re interested in getting a bit more detail about just how to use this visualization! Although I mentioned that my audience is primarily those already familiar with the data, this is not entirely true…with a bit of explaination, I think anyone could play around with this dashboard and make some interesting observations.&lt;/p&gt;
&lt;p&gt;So, with the basics of the data as described above in mind, I’ll begin by describing each element of the dashboard, starting from the left column and continuing counterclockwise. For now, please ignore the sliders and buttons (I know, it’s hard!).&lt;/p&gt;
&lt;div id=&#34;basic-metrics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Basic Metrics&lt;/h3&gt;
&lt;center&gt;
&lt;img src=&#34;images/basics.png&#34; alt=&#34;Basic Metrics&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;The element above is pretty straightforward – this is just some text that reports a couple of basic metrics about the data. The most basic, perhaps, is the overall mispronunciation detection accuracy, although it is important to note that we use balanced accuracy for this dataset. That is, instead of computing it using the typical accuracy formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[accuracy=\frac{total\text{ }correct}{total\text{ }examples}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;…it is calculated using the &lt;em&gt;average&lt;/em&gt; of the accuracies for each &lt;em&gt;individual&lt;/em&gt; class, as in the formula below:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[balanced\text{ }accuracy=\frac{1}{2}\left(\frac{total\text{ }mispronunciations\text{ }predicted\text{ } correctly}{total\text{ }mispronunciations}+\frac{total\text{ }correct\text{ }pronunciations\text{ }predicted\text{ } correctly}{total\text{ }correct\text{ }pronunciations}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wow, that’s a wordy equation! For a less-specific, more technical discussion of balanced accuracy, please check out &lt;a href=&#34;http://mvpa.blogspot.com/2015/12/balanced-accuracy-what-and-why.html&#34;&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Basically, this is used when a dataset has an imbalanced number of examples in each class, so that the accuracy of the model on one particular class does not overwhelm the others. We have a lot more correct pronunciations than mispronunciations in this dataset, which is why this is the metric we are using!&lt;/p&gt;
&lt;p&gt;The basic metrics section also reports on how many phonemes are assigned scores, therefore are used in the calculation of accuracy. The more strict a threshold chosen, the fewer phonemes are assigned scores…I will discuss this a bit more when I review the sliders and buttons. The number on the left is the total phonemes scored, and on the right is the total number of phonemes in the dataset, giving the proportion of how many phonemes were scored.&lt;/p&gt;
&lt;p&gt;The dashboard also reports (standard) accuracy for the phonological feature feedback. This is a bit complicated, but essentially, each phoneme has a set of expected phonological features expected to be present when that phoneme is realized in speech. A pronunciation error occurs when a realized phoneme does not match the phoneme expected, for example, someone may “fum” instead of “thumb”, substituting the “f” sound for the “th” sound. In this case, there are certain phonological features expected to be present or absent in the “th” sound that differ from the expectations for the “f” sound. If the system predicts a top error as one of the discrepancies between the actual and expected phoneme, we consider that a “correct” prediction, otherwise it is incorrect. From this information, we can calculate the feedback accuracy, however, it is important to note that feedback performance is only assessed for mispronounced phonemes which the system correctly identifies as mispronounced. In addition, the proportion of these phonemes that are assigned feedback is reported, in the same fashion as the proportion of phonemes assigned scores.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;binary-confusion-matrix&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Binary Confusion Matrix&lt;/h3&gt;
&lt;center&gt;
&lt;img src=&#34;images/binaryconf.png&#34; alt=&#34;Binary Confusion Matrix&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Although the confusion matrix was discussed briefly above, I’ll give a few more details here of how to go about reading this particular example. As labeled, the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-axis corresponds to correct, ground-truth labels, and the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis to the model-predicted labels. So, the top-left box corresponds to true negatives, or mispronounced phonemes correctly identified as mispronounced, whereas the bottom-left box corresponds to false positives, or mispronounced phonemes falsely identified as correctly pronounced. The upper-right box corresponds to false negatives, and the lower-right to true positives, defined as correctly pronounced phonemes mislabeled and correctly labeled, respectively.&lt;/p&gt;
&lt;p&gt;In this particular example, we can see that the majority of the examples are correctly labeled, however we do have 125 false positives, and 760 false negatives. The model still has room for improvement!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;phonological-feature-confusion-matrix&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Phonological Feature Confusion Matrix&lt;/h3&gt;
&lt;center&gt;
&lt;img src=&#34;images/bigconf.png&#34; alt=&#34;Phonological Features Confusion Matrix&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Wow, this is quite the figure! The general idea behind this figure is exactly the same as the figure depicted/described in the previous section, only we have many, many more classes here. Again, the upper-left to bottom-right diagonal corresponds to top phonological feature errors that were correctly identified by the model, and the other boxes to incorrect guesses. As we can see (if we squint!), we can make a number of observations about the model’s performance using this plot, for example, for the “coronal” feature, the system identifies this correctly a good portion of the time (908 times, to be exact), but does rather commonly mistakenly predict “lateral” as the top error when it should be “coronal”. Does this make sense? Well, we can consider what these features really mean: “coronal” refers to a sound which is articulated using the tip/blade of the tongue, specifically referring to the place of articulation, and “lateral” refers to sounds in which the center of the tongue contacts the roof of the mouth, so the flow air is forced through the sides of the vocal tract. So, it does seem reasonable that the model would get these somewhat similar qualities “confused”…interesting! As you can see, while this figure has a lot going on, close inspection can be rewarded with fascinating insights.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;feature-level-accuracy-for-phonological-feedback&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Feature-Level Accuracy for Phonological Feedback&lt;/h3&gt;
&lt;center&gt;
&lt;img src=&#34;images/barchart.png&#34; alt=&#34;Bar Chart&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;One may also be interested the overall accuracy of the for individual phonological features…well, here is the plot to answer all of those questions! This is a fairly simple bar chart, where each phonological feature that was predicted as an error in the current data subset is on the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-axis, and the percentage of instances where it was correctly predicted is on the &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;-axis. Using this plot, we can carefully determine whether the system performs better on certain phonological features than others, which may inform how to tweak the system or balance the input data in the future. We can see here that the system performs well on the “lateral” feature, but not so well on the “round” feature.&lt;/p&gt;
&lt;p&gt;For this type of analysis, it’s also important to know how many times each feature occured – a feature with 100% accuracy, but only one example, tells us much less than a feature with 97% accuracy over 100 examples. So, the frequency of each feature is listed under it’s label, and the features are arranged going left-to-right from most to least occurances.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;top-substitutions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Top Substitutions&lt;/h3&gt;
&lt;center&gt;
&lt;img src=&#34;images/tables.png&#34; alt=&#34;Tables&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Finally, there are a couple of tables reporting on the most frequent, specific phoneme substitutions in the dataset, as well as how accurately the model predicts them to be mispronounced. This, like the phonological feature confusion matrix, allows for detailed analyses of the model’s performance, for example, that commonly occuring substitutions are, fortunately, correctly identified most, if not all, of the time. It is important, though, to examine pairs for which the model does not perform well, as can be seen in the table on the right. Although some of these phonemes are quite seldom-occuring, it’s interesting to note that three of the pairs are vowel errors, and two are nasal consonont errors. Perhaps these are difficult problems for the model, in a larger sense. Certainly, this information can guide further analyses and questions about the model’s performance, and the data itself.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-to-click-the-buttons-and-move-the-dials&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Now, to click the buttons and move the dials!&lt;/h3&gt;
&lt;p&gt;Finally, the interactive part!&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;images/dials.png&#34; alt=&#34;Dials&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;There are several elements that can be adjusted in this dashboard, to examine certain subsets of the data. First, there are two sliders that can be used to adjust the confidence level thresholds used to determine which phonemes to deliver binary feedback on, as well as which mispronounciations to provide feature feedback for. As alluded to previously, the higher the threshold value, the stricter the system is, and the fewer phonemes are assigned feedback.&lt;/p&gt;
This thresholding impacts the entire dashboard, as it limits the data used to generate the figures to just the phonemes that satisfy these threshold requirements. As expected, a lax mispronunciation detection threshold of 0.2, or a minimum required confidence of 20%, will assign feedback to many phonemes, but may result in lower accuracy, whereas a strict threshold of 0.7 will only assign feedback for examples which the system is 70% “confident” in its decision (please excuse the anthropomorphization!), hopefully resulting in higher accuracy. Similar logic applies for the feedback assignment thresholding. Playing with different combinations help the user uncover yet more about the behavior of the system, and how it may be best utilized in practice.&lt;br /&gt;

&lt;center&gt;
&lt;img src=&#34;images/buttons.png&#34; alt=&#34;Buttons&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Finally, the user can decide whether they would like to work with the force-aligned, or manually segmented data, as well as subset it based on speaker’s diagnosis (again, TD refers to “typically-developing” and SD to &amp;quot;speech-disordered).&lt;/p&gt;
&lt;p&gt;I encourage you to play around with the data, and please let me know if you uncover anything particularly interesting!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;aesthetic-choices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aesthetic Choices&lt;/h2&gt;
&lt;p&gt;My main goal when considering the aesthetics of the visualization was to make it as calm and easy to digest as possible, to offset the large amount and wide variety of information present. Although we learned a lot of neat tricks in this class to customize color palettes and fonts, I ended up taking a “less is more” approach in this particular case.&lt;/p&gt;
&lt;p&gt;Specifically, I decided to continue with Shiny’s default color and font choices, and propogate them into the rest of the content. For the most part, this didn’t require much modification, other than changing some font sizes in the figures to better match those in the Shiny h*() elements, and pulling the pretty default blue used in the Shiny sliders/buttons into the plots.&lt;/p&gt;
&lt;p&gt;The tricker part was arranging the widgets/plots in the overall dashboard. I spent &lt;em&gt;a lot&lt;/em&gt; of time thinking through the best/most aesthetically pleasing way to arrange everything on the page, which had to be torn down and built back up several times as I added elements. I ended up arranging the page into three main sections; a bar across the top with the title, description, and toggles, the higher-level elements, and two evenly-sized columns containing the analyses. Having as few invisible “lines” breaking up the elements as possible really helped calm down the overall visual effect, in my opinion. I wish I had more to say about aesthetics, as it was something I put a lot of thought in to, but it manifested in a very simple way! I suppose I did use the lovely “theme_minimal()” option on my plots, but otherwise, I kept it clean and basic for a reason.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Methods&lt;/h2&gt;
&lt;p&gt;Now, on to methods. I began by briefly contemplating what I wanted to include in the dashboard, and then proceeded to dive right in, without thinking too much about aesthetics or layout at the outset. I ended up with an early version that looked something like this:&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;images/early_draft.png&#34; alt=&#34;Draft&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;I wasn’t happy with the layout at this point, it felt sort of uneven and clunky, with the bar chart front and center, and I didn’t feel like it deserved that much real estate. It was starting to get a little bit tricky to continue adding on additional subfigures, particularly knowing that I would have to rearrange eventually. It’s a somewhat challenging to arrange widgets in a Shiny application, especially without having a very solid plan of what the final layout would be, so I went, quite literally, back to the drawing board:&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;images/drawing.jpg&#34; alt=&#34;Drawing&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;I knew I wanted to have an even split down the middle of the page as much as possible, with a cohesive bar across the top with the higher-level details/interactive elements. Drawing it out really helped plan how to set up the fluidRow() functions in the ui() portion below, as some nesting was required. Thinking and planning it out before coding it up made the process much smoother.&lt;/p&gt;
&lt;p&gt;Although I did end up switching around the placement of a few elements, primarily reversing the placement of the two columns, the final product’s layout ended up very similar to my outlined vision!&lt;/p&gt;
&lt;p&gt;I’ve included the code corresponding to the final version below, with a few comments and details on a few of the more perplexing steps:&lt;/p&gt;
&lt;div id=&#34;data-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Processing:&lt;/h3&gt;
&lt;p&gt;Below are the steps that I took to preprocess my data after it was generated by the pronunciation analysis system. I do want to note that the raw form pulled into R, shown in the &lt;code&gt;glimpse()&lt;/code&gt; output in the Data section above, had already been preprocessed to a certain extent in the process of being generated. However, the model and related code is all written in Python, and is somewhat complex and, really, would require a whole separate blog post to detail the process, so I’ll leave those details out.&lt;/p&gt;
&lt;p&gt;There were still a couple of steps that needed to taken to prepare the data once it was pulled into R, which can be seen in the code below. One such modification was to tackle the issue of the names of the phonological features having been pulled in as abbreviations, as that is what is used in the Python program that generated the dataset. In order to make the dashboard a bit more useful, as I would guess not many could look at these abbreviations and immediately know the feature they correspond to, I mapped each one to its full name. This required first converting the columns from factors to characters, mapping each item, and then converting them back to factors, for use in a later plot. A couple of other columns were converted from factor variables to characters, for later processing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(gt)
library(ggpubr)
library(tidyverse)
library(ggplot2)
library(comprehenr)
library(yardstick)

# Mapper to convert feature abbreviations to full names.
feature_mapper &amp;lt;- function(abbreviation) {
    full &amp;lt;- case_when(abbreviation == &amp;#39;delrel&amp;#39; ~ &amp;quot;Delayed Release&amp;quot;,
                      abbreviation == &amp;#39;back&amp;#39; ~ &amp;quot;Back&amp;quot;, 
                      abbreviation == &amp;#39;cor&amp;#39; ~ &amp;quot;Coronal&amp;quot;,
                      abbreviation == &amp;#39;round&amp;#39; ~ &amp;quot;Round&amp;quot;,
                      abbreviation == &amp;#39;lo&amp;#39; ~ &amp;quot;Low&amp;quot;,
                      abbreviation == &amp;#39;voi&amp;#39; ~ &amp;quot;Voiced&amp;quot;,
                      abbreviation == &amp;#39;hi&amp;#39; ~ &amp;quot;High&amp;quot;,
                      abbreviation == &amp;#39;son&amp;#39; ~ &amp;quot;Sonorant&amp;quot;,
                      abbreviation == &amp;#39;syl&amp;#39; ~ &amp;quot;Syllabic&amp;quot;,
                      abbreviation == &amp;#39;labiodental&amp;#39; ~ &amp;quot;Labiodental&amp;quot;, 
                      abbreviation == &amp;#39;tense&amp;#39; ~ &amp;quot;Tense&amp;quot;,
                      abbreviation == &amp;#39;cont&amp;#39; ~ &amp;quot;Continuant&amp;quot;,
                      abbreviation == &amp;#39;pause&amp;#39; ~ &amp;quot;Pause&amp;quot;,
                      abbreviation == &amp;#39;ant&amp;#39; ~ &amp;quot;Anterior&amp;quot;,
                      abbreviation == &amp;#39;lat&amp;#39; ~ &amp;quot;Lateral&amp;quot;,
                      abbreviation == &amp;#39;front&amp;#39; ~ &amp;quot;Front&amp;quot;,
                      abbreviation == &amp;#39;nas&amp;#39; ~ &amp;quot;Nasal&amp;quot;,
                      abbreviation == &amp;#39;cons&amp;#39; ~ &amp;quot;Consonantal&amp;quot;, 
                      abbreviation == &amp;#39;lab&amp;#39; ~ &amp;quot;Labial&amp;quot;,
                      abbreviation == &amp;#39;distr&amp;#39; ~ &amp;quot;Distributed&amp;quot;,
                      abbreviation == &amp;#39;strid&amp;#39; ~ &amp;quot;Strident&amp;quot;,
                      abbreviation == &amp;#39;sg&amp;#39; ~ &amp;quot;Spread Glottis&amp;quot;)
    return(full)
}

# Read in both datasets. Could do this dynamically, 
# but then the datasets would be repeatedly read in.
# This way it is only done once.
data_child_fa &amp;lt;- read.csv(&amp;quot;data/phono_data_FA.csv&amp;quot;) %&amp;gt;%
    mutate(actual_phn = as.character(actual_phn),
           expected_phn = as.character(expected_phn),
           actual_top_error = as.character(actual_top_error),
           predicted_top_error = as.character(predicted_top_error)) %&amp;gt;%
    mutate(actual_top_error = feature_mapper(actual_top_error),
           predicted_top_error = feature_mapper(predicted_top_error)) %&amp;gt;%
    mutate(actual_top_error = as.factor(actual_top_error),
           predicted_top_error = as.factor(predicted_top_error))

data_child_manual &amp;lt;- read.csv(&amp;quot;data/phono_data_manual.csv&amp;quot;) %&amp;gt;%
    mutate(actual_phn = as.character(actual_phn),
           expected_phn = as.character(expected_phn),
           actual_top_error = as.character(actual_top_error),
           predicted_top_error = as.character(predicted_top_error)) %&amp;gt;%
    mutate(actual_top_error = feature_mapper(actual_top_error),
           predicted_top_error = feature_mapper(predicted_top_error)) %&amp;gt;%
    mutate(actual_top_error = as.factor(actual_top_error),
           predicted_top_error = as.factor(predicted_top_error))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;defining-the-user-interface&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Defining the User Interface:&lt;/h3&gt;
&lt;p&gt;Now, the trickiest part – defining the user interface! As I mentioned above, this was a complicated process which really benefited from careful, off-line thought as to how the layout should be mapped out on the page. Though the code doesn’t look like much, this was a fairly time consuming process.&lt;/p&gt;
&lt;p&gt;The first element is the title, which was the most straight-forward piece to add, unsurprisingly. After that, the first FluidRow element corresponds to the top row which extends across the whole page horizontally. Once I knew how I wanted this arranged, it wasn’t too painful to create. It did not require any nested rows, and could simply be divided into five columns containing each element: the instructional text, taking up half of the row space, the two threshold sliders, and the two sets of radio buttons to subset the data. Changes to these input widgets are monitored by the server logic and used to update the figures/tables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Define UI for application
ui &amp;lt;- fluidPage(
  
    # Title, at top left.
    titlePanel(&amp;quot;Data Exploration for Mispronunciation Detection System&amp;quot;),
    
    # Top row.
    fluidRow(
        column(6, h5(&amp;quot;This module allows a user to explore performance metrics 
                      for a prototype automatic mispronunciation detection system. The system scores
                      individual phonemes on overall pronunciation (correct/incorrect), and
                      assigns corrective feedback based on the most-likely phonological feature error.
                      The confidence threshold used to determine whether to assign an overall
                      score and feedback can be adjusted using the sliders on the right, higher 
                      values corresponding to higher confidence in the assessment.  
                      Phoneme alignment method and speaker diagnosis (TD: typically developing, SD:
                      speech disordered) can also be toggled.&amp;quot;)),
        column(2, sliderInput(&amp;quot;threshold_binary&amp;quot;, &amp;quot;Mispronunciation Detection:&amp;quot;,
                              min=0.0, max=0.90, value=0.5, step=0.05)),
        column(2, sliderInput(&amp;quot;threshold_feedback&amp;quot;, &amp;quot;Feedback Assignment:&amp;quot;,
                              min=0.0, max=0.90, value=0.5, step=0.05)),
        column(1, radioButtons(&amp;quot;type&amp;quot;, &amp;quot;Alignment:&amp;quot;, 
                              choices = c(&amp;quot;FA&amp;quot;, &amp;quot;Manual&amp;quot;))),
        column(1, radioButtons(&amp;quot;dx&amp;quot;, &amp;quot;Diagnosis:&amp;quot;, 
                               choices = c(&amp;quot;TD&amp;quot;, &amp;quot;SD&amp;quot;, &amp;quot;TD+SD&amp;quot;),
                               selected = &amp;quot;TD+SD&amp;quot;))),&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The remainder of the code for the UI section corresponds to the two columns underneath the top row. This process was more challenging, as it required nesting rows inside of columns to get the layout set up according to the plan I’d laid out. Nesting requires first segmenting the overall &lt;code&gt;fluidRow()&lt;/code&gt; element into the two columns, which are both set to be size 6 (the overall row is split into 12 sections, so each subsegment takes up half of the real estate). Then, each subsection is further divided into sections/rows. In the code for column #1, this can be seen inside of the outer column function, where there are two inner column calls, one used to display the textual performance metric output, which takes up 8 segments, or 2/3rds, of the width of this column (this corresponds to 1/2 * 2/3 = 1/3rd of the overall width of the application). The remaining third of the subsection contains the small confusion matrix. Then, for the large confusion matrix to be placed in the same column, under the items mentioned above, it is entered into the outer column function, after the inner column functions. Since this element was to take up the entire width of this subcolumn, it did not need to be placed inside of another column function.&lt;/p&gt;
&lt;p&gt;The second column is set up very similarly, please see the comments in the code for details.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    # Columns with figures/tables.
    fluidRow(
        # Column #1.
        column(6,
                    # Creating a nested row inside of the column.
                    column(8,
                      h3(&amp;quot;Overall Performance:&amp;quot;, style = &amp;quot;font-weight: 800&amp;quot;),
                      span(textOutput(&amp;quot;mp_accuracy&amp;quot;), style = &amp;quot;font-size: 16px&amp;quot;),
                      span(textOutput(&amp;quot;mp_accuracy_phonemes&amp;quot;), style = &amp;quot;font-size: 16px&amp;quot;),
                      span(textOutput(&amp;quot;pf_accuracy&amp;quot;), style = &amp;quot;font-size: 16px&amp;quot;),
                      span(textOutput(&amp;quot;pf_accuracy_phonemes&amp;quot;), style = &amp;quot;font-size: 16px&amp;quot;),
                      h2(&amp;quot; &amp;quot;)),
                    column(4,
                      br(),
                      plotOutput(&amp;quot;phn_conf_matrix&amp;quot;, height=&amp;quot;150px&amp;quot;),
                      h2(&amp;quot; &amp;quot;)),
                    # Placing the larger confusion matrix, placed under
                    # the row created above.
                    br(),
                    br(),
                    plotOutput(&amp;quot;pf_conf_matrix&amp;quot;, height=&amp;quot;500px&amp;quot;)),
        # Column #2.
        column(6,
               # Creating a nested row inside of the column.
               column(6,
                      gt_output(&amp;quot;top_substitutions_table&amp;quot;),
                      h2(&amp;quot; &amp;quot;)),
               column(6,
                      gt_output(&amp;quot;worst_top_substitutions_table&amp;quot;),
                      h2(&amp;quot; &amp;quot;)),
               # Placing the feature accuracy figure under the 
               # two tables.
               plotOutput(&amp;quot;feature_accuracy&amp;quot;)),
    )
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;defining-the-server-logic&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Defining the Server Logic:&lt;/h3&gt;
&lt;p&gt;Finally, the server logic! Here is where the information input via the slider and button widgets above is used to generate the dynamic plots and tables, which were placed in the UI section above. Each section corresponds to one output element, placed in a reactive context which allows for the item to be updated dynamically, and inside of the reactive context is the code that generates the plot or other output. For the most part, these are simple plots/tables and are pretty self-explanatory, with most of the code simply winnowing down the data to the necessary pieces. I’ve added a few comments here and there on the particularly interesting details:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;server &amp;lt;- function(input, output) {
  
    # Text output for mispronunciation detection accuracy. This must end with a
    # string, often combining variables that dynamically update, combined with 
    # the paste() function. The renderText() function wraps this code, creating
    # the reactive context.
    output$mp_accuracy &amp;lt;- renderText({
        mp_data &amp;lt;- current_data() %&amp;gt;% 
                   filter(predicted_score_conf &amp;gt;= input$threshold_binary) %&amp;gt;%
                   mutate(binary_accuracy = if_else(actual_score == predicted_score, 1, 0))
        mp_data_incorrect &amp;lt;- mp_data %&amp;gt;%
                             filter(actual_score == 0)
        mp_data_correct &amp;lt;- mp_data %&amp;gt;%
                           filter(actual_score == 1)
        mp_correct_0 &amp;lt;- sum(mp_data_incorrect$binary_accuracy)
        mp_total_0 &amp;lt;- nrow(mp_data_incorrect)
        mp_correct_1 &amp;lt;- sum(mp_data_correct$binary_accuracy)
        mp_total_1 &amp;lt;- nrow(mp_data_correct)
        mp_accuracy_0 &amp;lt;- round(mp_correct_0/mp_total_0,2)*100
        mp_accuracy_1 &amp;lt;- round(mp_correct_1/mp_total_1,2)*100
        mp_balanced_acc &amp;lt;- round((mp_accuracy_0 + mp_accuracy_1)/2, 2)
        paste(&amp;quot;Mispronunciation detection (balanced) accuracy: &amp;quot;, mp_balanced_acc, &amp;quot;%&amp;quot;, sep=&amp;quot;&amp;quot;)
    })
    
    # Dynamic text output for proportion of phonemes assigned scores.
    output$mp_accuracy_phonemes &amp;lt;- renderText({
        mp_data &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary) %&amp;gt;%
            mutate(binary_accuracy = if_else(actual_score == predicted_score, 1, 0))
        mp_total &amp;lt;- nrow(mp_data)
        mp_overall &amp;lt;- nrow(current_data())
        paste(&amp;quot;Phonemes assigned scores: &amp;quot;, mp_total, &amp;quot;/&amp;quot;, mp_overall, sep=&amp;quot;&amp;quot;)
    })
    
    # Dynamic text output for feature feedback accuracy.
    output$pf_accuracy &amp;lt;- renderText({
        pf_data &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary) %&amp;gt;%
            filter(actual_phn != &amp;#39;-&amp;#39;,
                   predicted_top_error_conf &amp;gt;= input$threshold_feedback,
                   actual_score == 0 &amp;amp; predicted_score == 0) %&amp;gt;%
            mutate(feedback_accuracy = if_else(predicted_top_error_validity == &amp;quot;True&amp;quot;, 1, 0))
        pf_correct &amp;lt;- sum(pf_data$feedback_accuracy)
        pf_total &amp;lt;- nrow(pf_data)
        paste(&amp;quot;Feedback accuracy: &amp;quot;, round(pf_correct/pf_total,2)*100, &amp;quot;%&amp;quot;,  sep=&amp;quot;&amp;quot;)
    })
    
    # Dynamic text output for feature feedback accuracy.
    output$pf_accuracy_phonemes &amp;lt;- renderText({
        pf_data &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary) %&amp;gt;%
            filter(actual_phn != &amp;#39;-&amp;#39;,
                   predicted_top_error_conf &amp;gt;= input$threshold_feedback,
                   actual_score == 0 &amp;amp; predicted_score == 0) %&amp;gt;%
            mutate(feedback_accuracy = if_else(predicted_top_error_validity == &amp;quot;True&amp;quot;, 1, 0))
        pf_data_all &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary) %&amp;gt;%
            filter(actual_phn != &amp;#39;-&amp;#39;,
                   actual_score == 0 &amp;amp; predicted_score == 0)
        pf_total &amp;lt;- nrow(pf_data)
        pf_overall &amp;lt;- nrow(pf_data_all)
        paste(&amp;quot;Mispronounced phonemes assigned feedback: &amp;quot;, pf_total, &amp;quot;/&amp;quot;, pf_overall, sep=&amp;quot;&amp;quot;)
    })
    
    # Bar chart showing individual feature accuracy.
    output$feature_accuracy &amp;lt;- renderPlot({
        # Dataframe including phonemes for which feedback was assigned, given
        # *binary* and *feedback* thresholds. Also ensures that the features
        # are ordered by frequency, so they are plotted in the correct order.
        pf_data &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary) %&amp;gt;%
            filter(actual_phn != &amp;#39;-&amp;#39;,
                   predicted_top_error_conf &amp;gt;= input$threshold_feedback,
                   actual_score == 0 &amp;amp; predicted_score == 0) %&amp;gt;%
            mutate(feedback_accuracy = if_else(predicted_top_error_validity == &amp;quot;True&amp;quot;, 1, 0)) %&amp;gt;% 
            group_by(predicted_top_error) %&amp;gt;%
            summarise(fb_acc = sum(feedback_accuracy),
                      fb_total = n()) %&amp;gt;%
            mutate(percent_correct = fb_acc/fb_total * 100) %&amp;gt;%
            arrange(desc(fb_total)) %&amp;gt;%
            ungroup() %&amp;gt;%
            mutate(predicted_top_error = as.character(predicted_top_error))
        
        x_labs_feature = pf_data$predicted_top_error
        x_labs_count = c(as.character(pf_data$fb_total))
        
        # Creating labels which include not only the feature name, but also the 
        # number of occurrances.
        x_labs &amp;lt;- to_list(for(index in seq(from = 1, to = length(x_labs_count))) 
                          paste(x_labs_feature[index], &amp;#39;\n&amp;#39;, x_labs_count[index], sep = &amp;quot;&amp;quot;))
        
        pf_plot &amp;lt;- pf_data %&amp;gt;%
                   ggplot(aes(x = predicted_top_error, y = percent_correct)) +
                   geom_col(color=rgb(66, 139, 202, max=255),
                            fill=rgb(66, 139, 202, max=255)) +
                   theme_minimal() +
                   xlab(&amp;quot;\nPredicted Top Phonological Error and # Occurrences&amp;quot;) +
                   ylab(&amp;quot;Percent Correct&amp;quot;) +
                   ggtitle(&amp;quot;Feature-level Accuracy of Assigned Phonological Feedback, by Frequency\n&amp;quot;) +
                   theme(plot.title = element_text(size = 16, face = &amp;quot;bold&amp;quot;, hjust=0.5),
                         axis.title = element_text(size = 14),
                         axis.text = element_text(size = 11)) +
                   scale_x_discrete(labels=x_labs)
        
        pf_plot
    })
    
    # Phonological feature onfusion matrix plot. This uses the *excellent*
    # yardstickr package&amp;#39;s conf_mat() function, which creates a textual
    # confusion matrix object which can be passed into the autoplot()
    # function to create a visual confusion matrix very easily. I love this!
    output$pf_conf_matrix &amp;lt;- renderPlot({
        data &amp;lt;- current_data() %&amp;gt;% 
          filter(predicted_score_conf &amp;gt;= input$threshold_binary) 
        conf_matrix &amp;lt;- conf_mat(data, actual_top_error, predicted_top_error,
                                dnn=c(&amp;quot;Prediction&amp;quot;,&amp;quot;Truth&amp;quot;))
        autoplot(conf_matrix, type=&amp;quot;heatmap&amp;quot;) +
          scale_y_discrete(position = &amp;quot;left&amp;quot;) +
          theme_minimal() +
          scale_fill_gradient(low = &amp;quot;white&amp;quot;, 
                              high = rgb(109,159,212, max=255)) +
          theme(axis.text.x = element_text(angle = 45,
                                           hjust = 1),
                legend.position = &amp;quot;right&amp;quot;,
                plot.title = element_text(size = 16, face = &amp;quot;bold&amp;quot;, hjust=0.5),
                axis.title = element_text(size = 14),
                axis.text = element_text(size = 11)) +
          ggtitle(&amp;quot;\nTop Phonological Feature Error Confusion Matrix\n&amp;quot;)
    })
    
    # Confusion matrix for binary mispronunciation detection. Uses
    # same method as above. So easy!
    output$phn_conf_matrix &amp;lt;- renderPlot({
      data &amp;lt;- current_data() %&amp;gt;%
        mutate(actual_score = as.factor(actual_score),
               predicted_score = as.factor(predicted_score))
      data &amp;lt;- data %&amp;gt;% 
        filter(predicted_score_conf &amp;gt;= input$threshold_binary) 
      conf_matrix &amp;lt;- conf_mat(data, actual_score, predicted_score)
      autoplot(conf_matrix, type=&amp;quot;heatmap&amp;quot;) +
        scale_y_discrete(position = &amp;quot;left&amp;quot;) +
        theme_minimal() +
        scale_fill_gradient(low = &amp;quot;white&amp;quot;, 
                            #high = rgb(66, 139, 202, max=255)) +
                            high = rgb(109,159,212, max=255)) +
        theme(axis.text.x = element_text(angle = 45,
                                         hjust = 0.5),
              title = element_text(hjust=0.5),
              legend.position = &amp;quot;right&amp;quot;) +
        ggtitle(&amp;quot;Binary Classification\nConfusion Matrix&amp;quot;)
    })
    
    # Creating the top substitutions table. This required the 
    # render_gt() context, a special reactive context specifically
    # for using the gt library&amp;#39;s table functions.
    output$top_substitutions_table &amp;lt;- render_gt({
        # Filter to actual substitutions, in total dataset.
        subs_data_raw &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary,
                   actual_phn != &amp;#39;-&amp;#39;) %&amp;gt;%
            filter(actual_phn != expected_phn,
                   actual_score == 0) %&amp;gt;%
            group_by(actual_phn, expected_phn) %&amp;gt;%
            summarise(total_subs = n(),
                      num_correctly_identified = n() - sum(predicted_score),
                      percent_correctly_identified = (num_correctly_identified/n())) %&amp;gt;%
            arrange(desc(total_subs))
        
        subs_data_raw %&amp;gt;% head(n=5) %&amp;gt;% ungroup() %&amp;gt;% gt() %&amp;gt;%
            tab_header(title = md(&amp;quot;**Top Overall Substitutions:**&amp;quot;)) %&amp;gt;%
            fmt_percent(columns = vars(percent_correctly_identified),
                       decimals = 2) %&amp;gt;%
            cols_label(actual_phn=&amp;quot;Actual\nPhoneme&amp;quot;, 
                       expected_phn=&amp;quot;Expected\nPhoneme&amp;quot;, 
                       total_subs=&amp;quot;Count&amp;quot;,
                       num_correctly_identified=&amp;quot;Correctly\nIdentified\n(#)&amp;quot;,
                       percent_correctly_identified=&amp;quot;Correctly\nIdentified\n(%)&amp;quot;) %&amp;gt;%
            tab_options(heading.title.font.weight = &amp;quot;bolder&amp;quot;,
                        heading.align = &amp;quot;left&amp;quot;,
                        table.font.size = 13,
                        table.border.top.color = &amp;quot;white&amp;quot;)
    })
    
    # Creating the top poorly-performing substitutions table. 
    # This also required the render_gt() context, but was 
    # otherwise pretty straightforward.
    output$worst_top_substitutions_table &amp;lt;- render_gt({
        # Filter to actual substitutions, in total dataset.
        subs_data_raw &amp;lt;- current_data() %&amp;gt;% 
            filter(predicted_score_conf &amp;gt;= input$threshold_binary,
                   actual_phn != &amp;#39;-&amp;#39;) %&amp;gt;%
            filter(actual_phn != expected_phn,
                   actual_score == 0) %&amp;gt;%
            group_by(actual_phn, expected_phn) %&amp;gt;%
            summarise(total_subs = n(),
                      num_correctly_identified = n() - sum(predicted_score),
                      percent_correctly_identified = (num_correctly_identified/n())) %&amp;gt;%
            arrange(desc(total_subs)) %&amp;gt;%
            filter(percent_correctly_identified &amp;lt; 0.5)
        
        subs_data_raw %&amp;gt;% head(n=5) %&amp;gt;% ungroup() %&amp;gt;% gt() %&amp;gt;%
            tab_header(title = md(&amp;quot;**Top Poorly-Performing Substitutions:**&amp;quot;)) %&amp;gt;%
            fmt_percent(columns = vars(percent_correctly_identified),
                        decimals = 2) %&amp;gt;%
            cols_label(actual_phn=&amp;quot;Actual\nPhoneme&amp;quot;, 
                       expected_phn=&amp;quot;Expected\nPhoneme&amp;quot;, 
                       total_subs=&amp;quot;Count&amp;quot;,
                       num_correctly_identified=&amp;quot;Correctly\nIdentified\n(#)&amp;quot;,
                       percent_correctly_identified=&amp;quot;Correctly\nIdentified\n(%)&amp;quot;) %&amp;gt;%
            tab_options(heading.title.font.weight = &amp;quot;bolder&amp;quot;,
                        heading.align = &amp;quot;left&amp;quot;,
                        table.font.size = 13,
                        table.border.top.color = &amp;quot;white&amp;quot;)
    })
    
    # A small reactive element which subsets the data according to the 
    # user&amp;#39;s selections. Separating this out just allows for cleaner 
    # code in the sections above.
    current_data &amp;lt;- reactive({
      data &amp;lt;- if(input$type == &amp;quot;FA&amp;quot;) data_child_fa else data_child_manual
      data &amp;lt;- if(input$dx == &amp;quot;TD&amp;quot;) data %&amp;gt;% filter(dx == &amp;quot;TD&amp;quot;) else data
      data &amp;lt;- if(input$dx == &amp;quot;SD&amp;quot;) data %&amp;gt;% filter(dx == &amp;quot;SD&amp;quot;) else data
    })
}

# Run the application 
shinyApp(ui = ui, server = server)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that concludes the discussion of this visualization! I hope you enjoyed learning about the process, as well as the data used and the project from which it came, I certainly had fun building the application and discussing the process.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Color with Coronavirus and Toilet Paper Data!</title>
      <link>https://vigilant-golick-64a677.netlify.app/post/tp-panic/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/post/tp-panic/</guid>
      <description>


&lt;p&gt;This post is an excerpt from a data visualization lab in which we experimented with use of colors in plots, both with positive and not-so-positive outcomes. In this post, I explore some good, bad, and greyscale color options, and briefly discuss the merits or faults of each. So, lets dive in!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;I know, I know, we’ve probably all seen enough coronavirus visualizations to last a lifetime, but here is one more! I was curious if the great toilet paper panic was a particularly American phenomenon, or if this was an anxiety that struck in the time of coronavirus regardless of nationality. To take a peek into this question, I used Google Trends (&lt;a href=&#34;https://trends.google.com/&#34; class=&#34;uri&#34;&gt;https://trends.google.com/&lt;/a&gt;) to gather data on search interest for coronavirus and toilet paper across three countries: China, Italy, and the United States, over the past 90 days. I figured this would make for an interesting color choice challenge, since we have three country variables, but each country has information on two different items, so we need to make a two-dimensional distinction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Getting data. Note, the data came in as three separate .csv&amp;#39;s, 
# I did some preliminary coalescing outside of R to get one single dataset.
tp_data &amp;lt;- read_csv(&amp;#39;data/tp_panic.csv&amp;#39;)

# Adjusting the data types from simple character/string types.
tp_data &amp;lt;- tp_data %&amp;gt;% 
  mutate(Country = as.factor(Country)) %&amp;gt;%
  mutate(Day = as.Date(Day, &amp;quot;%m/%d/%y&amp;quot;)) %&amp;gt;%
  mutate(coronavirus = case_when(coronavirus == &amp;#39;&amp;lt;1&amp;#39; ~ 0.5,
                              coronavirus != &amp;#39;&amp;lt;1&amp;#39; ~ as.numeric(coronavirus))) %&amp;gt;%
  mutate(toilet_paper = case_when(toilet_paper == &amp;#39;&amp;lt;1&amp;#39; ~ 0.5,
                              toilet_paper != &amp;#39;&amp;lt;1&amp;#39; ~ as.numeric(toilet_paper)))


glimpse(tp_data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 270
## Columns: 4
## $ Day          &amp;lt;date&amp;gt; 2020-01-17, 2020-01-18, 2020-01-19, 2020-01-20, 2020-01…
## $ Country      &amp;lt;fct&amp;gt; Italy, Italy, Italy, Italy, Italy, Italy, Italy, Italy, …
## $ toilet_paper &amp;lt;dbl&amp;gt; 0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0…
## $ coronavirus  &amp;lt;dbl&amp;gt; 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 8…&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;version-with-good-color&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version with &lt;em&gt;good&lt;/em&gt; color&lt;/h2&gt;
&lt;p&gt;Now, for the plotting, starting with a good color scheme!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cowplot)
library(ggpubr)

tp_plot_corona &amp;lt;- tp_data %&amp;gt;% ggplot(aes(Day, coronavirus, color = Country)) +
                       geom_line() +
                       scale_color_manual(values = c(&amp;#39;#FFC107&amp;#39;, &amp;#39;#C50049&amp;#39;, &amp;#39;#4897DC&amp;#39;)) +
                       ylab(&amp;quot;Coronavirus\nInterest&amp;quot;) +
                       xlab(&amp;quot;&amp;quot;) +
                       labs(title = &amp;quot;&amp;#39;Coronavirus&amp;#39; and &amp;#39;Toilet Paper&amp;#39;\nGoogle Search Interest Levels in Early 2020&amp;quot;) +
                       theme_minimal() 
  
tp_plot_tp &amp;lt;- tp_data %&amp;gt;% ggplot(aes(Day, toilet_paper, color = Country)) +
                       geom_line(alpha = 0.5) +
                       scale_color_manual(values = c(&amp;#39;#FFC107&amp;#39;, &amp;#39;#C50049&amp;#39;, &amp;#39;#4897DC&amp;#39;)) +
                       ylab(&amp;quot;Toilet Paper\nInterest&amp;quot;) +
                       xlab(&amp;quot;Date&amp;quot;) +
                       theme_minimal()

tp_plot_full &amp;lt;- ggarrange(tp_plot_corona, tp_plot_tp, heights = c(2, 0.8),
                    ncol = 1, nrow = 2, common.legend = TRUE, align = &amp;#39;v&amp;#39;,
                    legend = &amp;quot;right&amp;quot;) 

tp_plot_full&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://vigilant-golick-64a677.netlify.app/post/tp-panic/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The function below will check to see how these color selections will be percieved by folks with various types of colorblindness:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Seems to work ok for CVD!
cvd_grid(tp_plot_full)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://vigilant-golick-64a677.netlify.app/post/tp-panic/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Alright, that took way longer than it should have! This dataset ended up being really tricky to work with, but I think it was a good exercise in both how to use color to improve interpretation of a plot, but also how color can make a plot much more confusing (as will be demonstrated in the third plot). Although the plot is relatively simple, just six plotted lines, as mentioned above the relationships between the data/lines is a bit more complex than just six discrete/qualitative variables. Therefore, selecting six discrete colors would not make sense, as it would likely obfuscate the fact that each country had two sets of information/two lines, one for their interest/search frequency in/of coronavirus, and one for toilet paper. Connecting the two sets by country by means of color felt like a successful choice, because you can easily look at the two sets of lines and realize that the blue lines (indicating data belonging to the U.S.) show peaks occuring around the same time frame, which was the whole point of the plot. I opted to make the lines for the two different opacities, in order to still make it clear that they were indeed measuring two different things, despite being connected, although this felt like a secondary point, since I opted to create a subplot for the toilet paper data. I didn’t just choose that to offset the toilet paper data, however, I do think that the two different sets of dependent variables could have shared a common y-axis and been distinguished from each other using color, however, since the values for toilet paper interest were so much lower than for coronavirus, and the point was not to compare absolute values of one search term to the other (instead to see if they peaked at the same time), creating subplots in order to emphazise the peaks in the T.P. data made more sense to me. So, my overall take away from the visualization is that, yes, it does look like there was some coronavirus-related toilet paper panic in the United States, but not so much for China or Italy. Priorities!&lt;/p&gt;
&lt;p&gt;Full disclosure, I don’t &lt;em&gt;love&lt;/em&gt; the colors used in the plot above. I think they’re starting to veer into ugly territory, a little too saturated for my tastes. But, this blue/yellow/magenta palette seems to work best for colorblind viewers. I’ll need to keep playing around to find a color palette that I like that still works well for those with colorblindness.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-with-greyscale&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version with greyscale&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tp_plot_corona &amp;lt;- tp_data %&amp;gt;% ggplot(aes(Day, coronavirus, color = Country)) +
                       geom_line(linetype=&amp;quot;longdash&amp;quot;) +
                       scale_color_manual(values = c(&amp;#39;#000000&amp;#39;, &amp;#39;#808080&amp;#39;, &amp;#39;#D3D3D3&amp;#39;)) +
                       ylab(&amp;quot;Coronavirus\nInterest&amp;quot;) +
                       xlab(&amp;quot;&amp;quot;) +
                       labs(title = &amp;quot;&amp;#39;Coronavirus&amp;#39; and &amp;#39;Toilet Paper&amp;#39;\nGoogle Search Interest Levels in Early 2020&amp;quot;) +
                       theme_minimal() 
  
tp_plot_tp &amp;lt;- tp_data %&amp;gt;% ggplot(aes(Day, toilet_paper, color = Country)) +
                       geom_line(alpha = 1) +
                       scale_color_manual(values = c(&amp;#39;#000000&amp;#39;, &amp;#39;#808080&amp;#39;, &amp;#39;#D3D3D3&amp;#39;)) +
                       ylab(&amp;quot;Toilet Paper\nInterest&amp;quot;) +
                       xlab(&amp;quot;Date&amp;quot;) +
                       theme_minimal()

tp_plot_full &amp;lt;- ggarrange(tp_plot_corona, tp_plot_tp, heights = c(2, 0.8),
                    ncol = 1, nrow = 2, common.legend = TRUE, align = &amp;#39;v&amp;#39;,
                    legend = &amp;quot;right&amp;quot;) 

tp_plot_full&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://vigilant-golick-64a677.netlify.app/post/tp-panic/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hmm, I’m not as psyched about this one as I was the colored version. Since there are only three “hues” in the original, to distinguish the countries, it was pretty straightforward to translate those into greyscale in a way that ensures they are distinguishable (although I suppose the lightest value is a bit light, I think it is acceptable at least on a screen…I’d have to do some print tests to make sure it was ok in other mediums). Increasing the alpha for the T.P. subplot no longer worked well to set it off, since that made the greys less distinguishable…the increased overlap in the data also didn’t help. I still wanted an easy way for the eye to differentiate the lines in the top plot versus the bottom, and although, in my opinion, complexity in a plot works best when it increases top-to-bottom, making the lines in the bottom plot dashed was just as difficult to visually parse as when they were made more transparent…so I opted to make the top plot lines dashed. I think the greyscale setup works, but it’s not terribly groundbreaking or beautiful.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-with-dreadful-color&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version with &lt;em&gt;dreadful&lt;/em&gt; color&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tp_long &amp;lt;- tp_data %&amp;gt;%pivot_longer(c(coronavirus, toilet_paper), names_to = &amp;quot;searchterms&amp;quot;, values_to = &amp;quot;interest&amp;quot;) %&amp;gt;%
                      mutate(Country_SearchTerm = paste(Country, searchterms, sep = &amp;quot;: &amp;quot;),
                             Country = NULL,
                             searchterms = NULL)

tp_plot_bad &amp;lt;- tp_long %&amp;gt;% ggplot(aes(Day, interest, color = Country_SearchTerm)) +
                       geom_line() +
                       scale_color_manual(values = c(&amp;#39;#800000&amp;#39;, &amp;#39;#FF9999&amp;#39;, &amp;#39;#000075&amp;#39;, 
                                                     &amp;#39;#6666DB&amp;#39;, &amp;#39;#469990&amp;#39;, &amp;#39;#ACFFF6&amp;#39;)) +
                       ylab(&amp;quot;Search Interest&amp;quot;) +
                       xlab(&amp;quot;&amp;quot;) +
                       labs(title = &amp;quot;&amp;#39;Coronavirus&amp;#39; and &amp;#39;Toilet Paper&amp;#39;\nGoogle Search Interest Levels in Early 2020&amp;quot;) +
                       theme_minimal()

tp_plot_bad&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://vigilant-golick-64a677.netlify.app/post/tp-panic/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Above was my original attempt at this plot…I had good intentions – my goal was still wanted to link the data together by country, but I ended up separating the coronavirus data from the T.P. data by lightening the colors 40% (according to &lt;a href=&#34;https://www.hexcolortool.com/#479a90&#34; class=&#34;uri&#34;&gt;https://www.hexcolortool.com/#479a90&lt;/a&gt;). Wow, this resulted in some ugly colors, and really difficult to see not only due to color, but also due to the relative values/heights of the datasets. Additionally, simply lightening the colors does not guarantee that the darker and lighter versions will feel intuitively cohesive, in fact, Italy and the U.S.’s colors begin to look like a spectrum when they are broken down into a light and dark version each (this can be observed best in the legend)…which is definitely not something that makes sense with this data. Also, this would not work well for a colorblind viewer…overall, this is a much less effective plot than the original, in my opinion!&lt;/p&gt;
&lt;p&gt;There we have it, a short exploration of color choice in at least one type of line plot. Happy plotting!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Exploring COVID-19 Data with Shiny!</title>
      <link>https://vigilant-golick-64a677.netlify.app/post/covid-shiny/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/post/covid-shiny/</guid>
      <description>


&lt;p&gt;For this post, I want to showcase my first interactive Shiny app, both the final product, and below it, the code used to generate the application. Although yes, this does use more COVID data, it was a very nice exploration of how to go about using Shiny, and I must say, after working with it, I think it’s a tool that I will start using often to explore large datasets!&lt;/p&gt;
&lt;div id=&#34;the-application&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Application:&lt;/h3&gt;
&lt;iframe src=&#34;https://amie-roten.shinyapps.io/lab7/&#34; width=&#34;960&#34; height=&#34;800px&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;This application uses Kieran Healy’s &lt;code&gt;covdata&lt;/code&gt; package, a comprehensive collection of data relating to the Coronavirus pandemic. I decided to use the Apple U.S. Mobility dataset, specifically the vehicular-travel data, to create the application above. The app includes three identical widgets that can be used to select three different states in order to compare and contrast the data. The widgets’ upper plots show the daily case increase, and the bottom plot shows the daily mobility index, that is how the day’s mobility data differs from the baseline taken in January. The yellow indicates a lower level of travel for that particular day, and the green indicates more travel. Please explore the application and see what interesting observations you can make!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Code:&lt;/h3&gt;
&lt;p&gt;Below is the code used to generate the Shiny app&lt;/p&gt;
&lt;p&gt;The first section is simply the data wrangling process, processing the raw data in the &lt;code&gt;covdata&lt;/code&gt; package in order to get it in the correct format for use in the plots. This is not an inherant piece of creating a Shiny application, but it useful to demonstrate the process of reshaping and winnowing down the dataset for this particular use!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(shiny)
library(gt)
library(covdata)
library(ggpubr)
library(tidyverse)

case_data &amp;lt;- nytcovstate
locations &amp;lt;- sort(unique(case_data$state))
mobility_data &amp;lt;- apple_mobility %&amp;gt;%
                 filter(region %in% locations) %&amp;gt;%
                 select(-alternative_name, -geo_type) %&amp;gt;%
                 mutate(state = region,
                        region = NULL)

data &amp;lt;- full_join(mobility_data, case_data) %&amp;gt;%
        mutate(fips = replace_na(fips, 0),
               cases = replace_na(cases, 0),
               deaths = replace_na(deaths, 0)) %&amp;gt;%
        group_by(state) %&amp;gt;% 
        arrange(date, .by_group = TRUE) %&amp;gt;%
        mutate(daily_cases = (cases - (lag(cases)))) %&amp;gt;%
        ungroup() %&amp;gt;%
        mutate(daily_cases = replace_na(daily_cases, 0))

transpo &amp;lt;- c(unique(data$transportation_type))
vec_brks &amp;lt;- c(-50, 0, 50)
vec_labs &amp;lt;- vec_brks + 100
start_date &amp;lt;- sort(data$date)[1]
end_date &amp;lt;- sort(desc(data$date))[1]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating a Shiny application requires two main components, the &lt;code&gt;ui&lt;/code&gt; componant, which is where the application creator can both tweak the layout of the application, as well as create interactive elements where the user can select from a number of options. For example, &lt;code&gt;dateRangeInput()&lt;/code&gt; creates a widget where the user can enter a range of dates. The creator can select what the possible range can be, eliminate possibility for invalid date selections. There are many different input functions, and the elements can be arranged in many configurations in order to get the app looking just right! It’s a wonderland (and/or a real time-sink) for people like me who get endless satisfaction from minor nudges and adjustments to get things looking just right. :D&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ui &amp;lt;- fluidPage(
titlePanel(&amp;quot;Apple U.S. Mobility Dataset during COVID-19 Crisis&amp;quot;),

fluidRow(
   column(5, h3(&amp;quot;Please begin by selecting your desired date range: &amp;quot;)),
   column(3, dateRangeInput(&amp;#39;dateRange&amp;#39;, label = &amp;#39;&amp;#39;, format=&amp;#39;mm-dd-yyyy&amp;#39;, 
                            separator=&amp;#39; to &amp;#39;, start = &amp;#39;2020-01-13&amp;#39;, 
                            end = &amp;#39;2020-05-13&amp;#39;, min = &amp;#39;2020-01-13&amp;#39;, 
                            max = &amp;#39;2020-05-13&amp;#39;)),
   column(4, h5(&amp;quot;Upper plot displays the daily increase in COVID-19 
                 cases for selected location. Lower plot shows 
                 corresponding Apple Maps&amp;#39; mobility data, in terms 
                 of trends in driving since mid-January 2020 (dark 
                 green indicates a relative increase, yellow indicates 
                 a relative decrease). Did less driving correspond to 
                \&amp;quot;flattening the curve\&amp;quot;? We can find out!&amp;quot;))
),

hr(),

fluidRow(
   column(4, plotOutput(&amp;quot;plot1&amp;quot;)),
   column(4, plotOutput(&amp;quot;plot2&amp;quot;)),
   column(4, plotOutput(&amp;quot;plot3&amp;quot;))
),

fluidRow(
   column(3, offset = 1, selectInput(&amp;quot;loc1&amp;quot;, label=&amp;quot;Location 1&amp;quot;, 
                                     multiple=FALSE, locations, 
                                     width=&amp;#39;70%&amp;#39;, size=5, selectize=FALSE)),
   column(3, offset = 1, selectInput(&amp;quot;loc2&amp;quot;, label=&amp;quot;Location 2&amp;quot;, 
                                     multiple=FALSE, locations, 
                                     width=&amp;#39;70%&amp;#39;, size=5, selectize=FALSE)),
   column(3, offset = 1, selectInput(&amp;quot;loc3&amp;quot;, label=&amp;quot;Location 3&amp;quot;, 
                                     multiple=FALSE, locations, 
                                     width=&amp;#39;70%&amp;#39;, size=5, selectize=FALSE)),
),

h5(&amp;quot;Data from Kieran Healy&amp;#39;s covdata package: https://kjhealy.github.io/covdata/. 
   Bottom plots *very heavily* inspired by apple_mobility dataset vignette!&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second main component is the &lt;code&gt;server&lt;/code&gt; section. This is where the dynamic outputs such as plots, text, and other elements, are created and updated, and then can be placed via the &lt;code&gt;ui&lt;/code&gt; section. In this case, we have six plots (three sets of two) which use input from the selection widgets in the section above to dynamically change and reflect the subset of the data the user would like to see.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;server &amp;lt;- function(input, output, session) {
   
output$plot1 &amp;lt;- renderPlot({
   case_plot1 &amp;lt;- data %&amp;gt;%
      filter(state == input$loc1,
             #transportation_type %in% transpo_filter(),
             date &amp;gt;= input$dateRange[1] &amp;amp; date &amp;lt;= input$dateRange[2]) %&amp;gt;%
      ggplot(mapping=aes(x=date, y=daily_cases)) +
      geom_line() +
      scale_y_log10(limits=c(1, 3000)) +
      theme(legend.position = &amp;quot;none&amp;quot;) +
      xlab(&amp;quot;&amp;quot;) +
      ylab(&amp;quot;Daily Case\nIncrease&amp;quot;)
   
     mobi_plot1 &amp;lt;- data %&amp;gt;% 
     filter(state == input$loc1,
            #transportation_type %in% transpo_filter(),
            date &amp;gt;= input$dateRange[1] &amp;amp; date &amp;lt;= input$dateRange[2]) %&amp;gt;% 
     mutate(over_under = index &amp;lt; 100,
              index = index - 100) %&amp;gt;%
     ggplot(mapping=aes(x=date, y=index, fill=over_under, col=over_under)) +
     geom_col() +
     scale_color_manual(values = c(&amp;#39;#004D40&amp;#39;, &amp;#39;#FFC107&amp;#39;)) +
     scale_fill_manual(values = c(&amp;#39;#004D40&amp;#39;, &amp;#39;#FFC107&amp;#39;)) +
     theme(legend.position = &amp;quot;none&amp;quot;) +
     scale_y_continuous(limits = c(-150, 150)) +
     geom_hline(yintercept = 0, color = &amp;quot;gray40&amp;quot;) +
     xlab(&amp;quot;Date&amp;quot;) +
     ylab(&amp;quot;Mobility Index&amp;quot;)
     
     ggarrange(case_plot1, mobi_plot1, heights = c(0.8, 2),
               ncol = 1, nrow = 2, align = &amp;#39;v&amp;#39;,
               legend = NULL) 
 })
 
output$plot2 &amp;lt;- renderPlot({
   case_plot2 &amp;lt;- data %&amp;gt;%
      filter(state == input$loc2,
             #transportation_type %in% transpo_filter(),
             date &amp;gt;= input$dateRange[1] &amp;amp; date &amp;lt;= input$dateRange[2]) %&amp;gt;%
      ggplot(mapping=aes(x=date, y=daily_cases)) +
      geom_line() +
      scale_y_log10(limits=c(1, 3000)) +
      theme(legend.position = &amp;quot;none&amp;quot;) +
      xlab(&amp;quot;&amp;quot;) +
      ylab(&amp;quot;Daily Case\nIncrease&amp;quot;)
   
   mobi_plot2 &amp;lt;- data %&amp;gt;% 
      filter(state == input$loc2,
             #transportation_type %in% transpo_filter(),
             date &amp;gt;= input$dateRange[1] &amp;amp; date &amp;lt;= input$dateRange[2]) %&amp;gt;% 
      mutate(over_under = index &amp;lt; 100,
             index = index - 100) %&amp;gt;%
      ggplot(mapping=aes(x=date, y=index, fill=over_under, col=over_under)) +
      geom_col() +
      theme(legend.position = &amp;quot;none&amp;quot;) +
      scale_y_continuous(limits = c(-150, 150)) +
      scale_color_manual(values = c(&amp;#39;#004D40&amp;#39;, &amp;#39;#FFC107&amp;#39;)) +
      scale_fill_manual(values = c(&amp;#39;#004D40&amp;#39;, &amp;#39;#FFC107&amp;#39;)) +
      geom_hline(yintercept = 0, color = &amp;quot;gray40&amp;quot;) +
      xlab(&amp;quot;Date&amp;quot;) +
      ylab(&amp;quot;Mobility Index&amp;quot;)
   
   ggarrange(case_plot2, mobi_plot2, heights = c(0.8, 2),
             ncol = 1, nrow = 2, align = &amp;#39;v&amp;#39;,
             legend = NULL) 
})


output$plot3 &amp;lt;- renderPlot({
   case_plot3 &amp;lt;- data %&amp;gt;%
      filter(state == input$loc3,
             #transportation_type %in% transpo_filter(),
             date &amp;gt;= input$dateRange[1] &amp;amp; date &amp;lt;= input$dateRange[2]) %&amp;gt;%
      ggplot(mapping=aes(x=date, y=daily_cases)) +
      theme(legend.position = &amp;quot;none&amp;quot;) +
      scale_y_log10(limits=c(1, 3000)) +
      geom_line() +
      xlab(&amp;quot;&amp;quot;) +
      ylab(&amp;quot;Daily Case\nIncrease&amp;quot;)
   
   mobi_plot3 &amp;lt;- data %&amp;gt;% 
      filter(state == input$loc3,
             #transportation_type %in% transpo_filter(),
             date &amp;gt;= input$dateRange[1] &amp;amp; date &amp;lt;= input$dateRange[2]) %&amp;gt;% 
      mutate(over_under = index &amp;lt; 100,
             index = index - 100) %&amp;gt;%
      ggplot(mapping=aes(x=date, y=index, fill=over_under, col=over_under)) +
      geom_col() +
      theme(legend.position = &amp;quot;none&amp;quot;) +
      scale_color_manual(values = c(&amp;#39;#004D40&amp;#39;, &amp;#39;#FFC107&amp;#39;)) +
      scale_fill_manual(values = c(&amp;#39;#004D40&amp;#39;, &amp;#39;#FFC107&amp;#39;)) +
      scale_y_continuous(limits = c(-150, 150)) +
      geom_hline(yintercept = 0, color = &amp;quot;gray40&amp;quot;) +
      xlab(&amp;quot;Date&amp;quot;) +
      ylab(&amp;quot;Mobility Index&amp;quot;)
   
   ggarrange(case_plot3, mobi_plot3, heights = c(0.8, 2),
             ncol = 1, nrow = 2, align = &amp;#39;v&amp;#39;,
                             legend = NULL) 
})

}

shinyApp(ui = ui, server = server)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I did not go into much depth explaining the ins-and-outs of creating a Shiny app, but hopefully this gives a quick taste of what can be done with the library, and inspires you to make a Shiny app of your own! More information on how to use Shiny can be found here: &lt;a href=&#34;https://shiny.rstudio.com/tutorial/&#34; class=&#34;uri&#34;&gt;https://shiny.rstudio.com/tutorial/&lt;/a&gt;, and in many places on the web.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Investigating PDX Flights Data using Tables!</title>
      <link>https://vigilant-golick-64a677.netlify.app/post/pdx-flights/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/post/pdx-flights/</guid>
      <description>


&lt;p&gt;This post is devoted to answering a couple of questions about flights in and out of PDX, in the form of custom R tables (primarily using the fantastic &lt;code&gt;gt&lt;/code&gt; library!). Not only will the questions be answered and tables displayed, but the code for how to wrangle the data and build the tables is included, as well as some narration on what did and did not work. On we go!&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;analysis-1-most-traveled-destination-per-month&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Analysis #1: Most Traveled Destination, per Month&lt;/h3&gt;
&lt;p&gt;I’d like to take a look at which destinations departing from PDX are the most frequently travelled, broken down by month, along with the flight count for each destination. It’s tricky to make predictions, but I’d think that a destination like Hawaii or Florida might be more popular in the cooler months, whereas more exotic, internations locations like London or Japan might be more popular in the warmer months, corresponding to the summertime where many tend to take longer trips. But, let’s take a look and find out!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pdx_flights_dest &amp;lt;- flights %&amp;gt;%
               filter(origin == &amp;quot;PDX&amp;quot;) %&amp;gt;%
               group_by(month, dest) %&amp;gt;%
               summarise(n = n()) %&amp;gt;%
               group_by(month) %&amp;gt;%
               top_n(1, n)
pdx_flights_dest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 3
## # Groups:   month [12]
##    month dest      n
##    &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1     1 SFO     446
##  2     2 SFO     389
##  3     3 SFO     462
##  4     4 SFO     450
##  5     5 SFO     464
##  6     6 SFO     440
##  7     7 SFO     432
##  8     8 SFO     437
##  9     9 SFO     438
## 10    10 SFO     442
## 11    11 SFO     391
## 12    12 SFO     388&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wow…what a terribly dull outcome, not particularly table-worthy. Let’s try excluding San Francisco and see what shakes out. We’ll take a chance and go ahead and print this information in an attractive table format, using the &lt;code&gt;gt&lt;/code&gt; library:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pdx_flights_dest_noSF &amp;lt;- flights %&amp;gt;%
               filter(origin == &amp;quot;PDX&amp;quot;) %&amp;gt;%
               arrange(month) %&amp;gt;%
               group_by(month, dest) %&amp;gt;%
               summarise(n = n()) %&amp;gt;%
               group_by(month) %&amp;gt;%
               filter(dest != &amp;quot;SFO&amp;quot;) %&amp;gt;%
               top_n(1, n) %&amp;gt;%
               ungroup() %&amp;gt;%
               mutate(month = month.name[month])

pdx_flights_dest_noSF&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 3
##    month     dest      n
##    &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
##  1 January   DEN     323
##  2 February  DEN     276
##  3 March     LAX     346
##  4 April     LAX     348
##  5 May       LAX     387
##  6 June      DEN     354
##  7 July      DEN     359
##  8 August    DEN     373
##  9 September DEN     369
## 10 October   DEN     366
## 11 November  DEN     295
## 12 December  PHX     286&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pdx_flights_dest_noSF_gt &amp;lt;- pdx_flights_dest_noSF %&amp;gt;% gt() %&amp;gt;%
                       # NOTE: While these options add striping when the 
                       # .Rmd file is rendered locally, the striping is not
                       # present when deployed. Oddly, removing this option
                       # *adds* striping to deployed file. The more you know!
                       # tab_options(row.striping.background_color = &amp;quot;#f9f9f9&amp;quot;,
                       #             row.striping.include_table_body = TRUE,
                       #             row.striping.include_stub = TRUE) %&amp;gt;%
                       tab_header(title=&amp;quot;Top Destinations out of PDX, By Month&amp;quot;,
                                  subtitle=&amp;quot;(Excluding SFO)&amp;quot;) %&amp;gt;%
                       cols_label(month = &amp;quot;Month&amp;quot;, 
                                  dest = &amp;quot;Destination&amp;quot;, 
                                  n = &amp;quot;Number of Flights&amp;quot;) %&amp;gt;%
                       cols_align(align = &amp;quot;center&amp;quot;,
                                  columns = vars(dest))
                       
                       

pdx_flights_dest_noSF_gt&lt;/code&gt;&lt;/pre&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#hmdvzkpslj .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#hmdvzkpslj .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hmdvzkpslj .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#hmdvzkpslj .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#hmdvzkpslj .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hmdvzkpslj .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hmdvzkpslj .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#hmdvzkpslj .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#hmdvzkpslj .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#hmdvzkpslj .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#hmdvzkpslj .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#hmdvzkpslj .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#hmdvzkpslj .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#hmdvzkpslj .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#hmdvzkpslj .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#hmdvzkpslj .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#hmdvzkpslj .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#hmdvzkpslj .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#hmdvzkpslj .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hmdvzkpslj .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#hmdvzkpslj .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hmdvzkpslj .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#hmdvzkpslj .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hmdvzkpslj .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hmdvzkpslj .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#hmdvzkpslj .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hmdvzkpslj .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#hmdvzkpslj .gt_left {
  text-align: left;
}

#hmdvzkpslj .gt_center {
  text-align: center;
}

#hmdvzkpslj .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#hmdvzkpslj .gt_font_normal {
  font-weight: normal;
}

#hmdvzkpslj .gt_font_bold {
  font-weight: bold;
}

#hmdvzkpslj .gt_font_italic {
  font-style: italic;
}

#hmdvzkpslj .gt_super {
  font-size: 65%;
}

#hmdvzkpslj .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;hmdvzkpslj&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;3&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;Top Destinations out of PDX, By Month&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;3&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;(Excluding SFO)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Month&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Destination&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Number of Flights&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;January&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;323&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;February&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;276&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;March&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;346&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;April&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;May&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;387&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;June&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;354&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;July&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;359&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;August&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;373&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;September&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;369&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;October&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;366&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;November&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;295&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;December&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;PHX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;286&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;I suppose this is somewhat interesting in a couple of respects. First, we can see that, at least judging by the count for the top destination, the airport is busier during the warmer months, with November through February having markedly fewer flights than the other part of the year. We can see that Denver is a popular/common destination year-round (I think PDX-DEN is a big Frontier route, often on my way to visit family Illinois I end up with a layover there). But, during the cooler months, the destinations sway a bit warmer; Los Angeles and Phoenix.&lt;/p&gt;
&lt;p&gt;I chose to use &lt;code&gt;gt&lt;/code&gt; since I really like the clean look and simplicity of the tables it generates, especially for a straightforward dataset like this one. I didn’t end up changing the defaults much, since I liked the column/row separations already. I did center the destination column, as it was left-aligned by default, and butted up against the months a bit too much. The destination and flight number columns make clean lines, and it is easy to read them up-and-down, and that really is the most important comparison here; how each column relates to the next sequentially/temporily, not necessarily how the destination relates to its’ associated number of flights.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-2-finding-busy-aircraft&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Analysis #2: Finding Busy Aircraft&lt;/h3&gt;
&lt;p&gt;I am a nervous flyer, and definitely notice the wear and tear on a plane before I get on it…the longer it’s been in the air, the more reliable it has shown itself to be? So I tell myself…hah! But, I thought this was an interesting line of investigation. I’m going to make a table that displays the top five aircraft with the most flight time accumulated, and also include the associated airline, and the top two routes each aircraft flies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pdx_flights_aircraft &amp;lt;- flights %&amp;gt;% 
                        filter(origin == &amp;quot;PDX&amp;quot;, tailnum!=&amp;quot;&amp;quot;) %&amp;gt;%
                        select(tailnum, dest, air_time, carrier) %&amp;gt;%
                        group_by(tailnum, carrier, dest) %&amp;gt;%
                        summarize(airtime = sum(air_time)) %&amp;gt;%
                        add_count(name = &amp;quot;total_airtime&amp;quot;, wt=airtime) %&amp;gt;%
                        arrange(desc(total_airtime), desc(airtime)) 

first_set = seq(1, 15, by=3)
second_set = seq(2, 15, by=3)
third_set = seq(3, 15, by=3)

pdx_flights_aircraft_filtered &amp;lt;- pdx_flights_aircraft %&amp;gt;%
                        filter(total_airtime %in% unique(pdx_flights_aircraft$total_airtime)[1:5]) %&amp;gt;%
                        group_by(tailnum) %&amp;gt;%
                        top_n(3, wt = airtime) %&amp;gt;%
                        select(-airtime) %&amp;gt;%
                        mutate(dest_rank = case_when(row_number() %in% first_set ~ &amp;quot;dest_1&amp;quot;,
                                                     row_number() %in% second_set ~ &amp;quot;dest_2&amp;quot;, 
                                                     row_number() %in% third_set ~ &amp;quot;dest_3&amp;quot;)) %&amp;gt;%
                        pivot_wider(names_from = dest_rank, values_from = dest) %&amp;gt;%
                        mutate(carrier = ifelse(carrier == &amp;#39;OO&amp;#39;, &amp;quot;SkyWest&amp;quot;, &amp;quot;Alaska&amp;quot;)) %&amp;gt;%
                        ungroup()
                      
pdx_flights_aircraft_filtered %&amp;gt;% gt() %&amp;gt;%
                       # tab_options(row.striping.background_color = &amp;quot;#f9f9f9&amp;quot;,
                       #             row.striping.include_table_body = TRUE,
                       #             row.striping.include_stub = TRUE) %&amp;gt;%
                       tab_header(title=&amp;quot;Busiest Aircraft, by Total Airtime&amp;quot;) %&amp;gt;%
                       tab_spanner(label = &amp;quot;Aircraft Details&amp;quot;,
                                   columns = vars(tailnum, carrier, total_airtime)) %&amp;gt;%
                       tab_spanner(label = &amp;quot;Busiest Routes&amp;quot;,
                                  columns = vars(dest_1, dest_2, dest_3)) %&amp;gt;%
                       cols_label(tailnum = &amp;quot;Tail\nNumber&amp;quot;,
                                  carrier = &amp;quot;Carrier&amp;quot;,
                                  total_airtime = &amp;quot;Total Airtime \n (min)&amp;quot;,
                                  dest_1 = &amp;quot;First&amp;quot;,
                                  dest_2 = &amp;quot;Second&amp;quot;,
                                  dest_3 = &amp;quot;Third&amp;quot;) %&amp;gt;%
                       cols_align(align = &amp;quot;center&amp;quot;,
                                  columns = vars(total_airtime, dest_1, dest_2))&lt;/code&gt;&lt;/pre&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#dpkhpgzsnp .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#dpkhpgzsnp .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dpkhpgzsnp .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#dpkhpgzsnp .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#dpkhpgzsnp .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dpkhpgzsnp .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dpkhpgzsnp .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#dpkhpgzsnp .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#dpkhpgzsnp .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#dpkhpgzsnp .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#dpkhpgzsnp .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#dpkhpgzsnp .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#dpkhpgzsnp .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#dpkhpgzsnp .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#dpkhpgzsnp .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#dpkhpgzsnp .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#dpkhpgzsnp .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#dpkhpgzsnp .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#dpkhpgzsnp .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dpkhpgzsnp .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#dpkhpgzsnp .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dpkhpgzsnp .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#dpkhpgzsnp .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dpkhpgzsnp .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dpkhpgzsnp .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#dpkhpgzsnp .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dpkhpgzsnp .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#dpkhpgzsnp .gt_left {
  text-align: left;
}

#dpkhpgzsnp .gt_center {
  text-align: center;
}

#dpkhpgzsnp .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#dpkhpgzsnp .gt_font_normal {
  font-weight: normal;
}

#dpkhpgzsnp .gt_font_bold {
  font-weight: bold;
}

#dpkhpgzsnp .gt_font_italic {
  font-style: italic;
}

#dpkhpgzsnp .gt_super {
  font-size: 65%;
}

#dpkhpgzsnp .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;dpkhpgzsnp&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;6&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;Busiest Aircraft, by Total Airtime&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;6&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_center gt_columns_top_border gt_column_spanner_outer&#34; rowspan=&#34;1&#34; colspan=&#34;3&#34;&gt;
        &lt;span class=&#34;gt_column_spanner&#34;&gt;Aircraft Details&lt;/span&gt;
      &lt;/th&gt;
      &lt;th class=&#34;gt_center gt_columns_top_border gt_column_spanner_outer&#34; rowspan=&#34;1&#34; colspan=&#34;3&#34;&gt;
        &lt;span class=&#34;gt_column_spanner&#34;&gt;Busiest Routes&lt;/span&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Tail
Number&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Carrier&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Total Airtime 
 (min)&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;First&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Second&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Third&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;N225AG&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;SkyWest&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;34805&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;ONT&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;BUR&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;TUS&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;N219AG&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;SkyWest&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;31167&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;BUR&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;TUS&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;SBA&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;N614AS&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;Alaska&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;28931&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SNA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAS&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;SFO&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;N611AS&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;Alaska&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;27697&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SNA&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAS&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;ORD&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;N216AG&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;SkyWest&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;27471&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;BUR&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;ONT&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_left&#34;&gt;SBA&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;This was a pretty fun, but involved task. I first played a bit with &lt;code&gt;kable&lt;/code&gt; in an attempt to do something different, but it just didn’t make a very attractive table, so I switched back to &lt;code&gt;gt&lt;/code&gt;. Since there are a number of different types of information included in this table, I decided to make use of the &lt;code&gt;tab_spanner&lt;/code&gt; option to call attention to that fact and do a bit of grouping. Then, I added striping, since in this case, the important grouping is by row, not necessarily comparing each row to each other, so I decided to encourage horizontal scanning of the table using this method.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis-3-time-of-day&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Analysis #3 Time of Day&lt;/h3&gt;
&lt;p&gt;I’m curious to see whether certain destinations commonly correspond to morning, afternoon/evening, or red-eye flights, and also the relative representation of each type of flight. I’ll consider flights that leave between 5-11am morning flights, 11-8pm afternoon/evening flights, and the remainder red-eye flights (although these distinctions may not be perfect). I think this table is going to end up looking rather similar to the one above…we will see.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_set = seq(1, 15, by=5)
second_set = seq(2, 15, by=5)
third_set = seq(3, 15, by=5)
fourth_set = seq(4, 15, by=5)
fifth_set = seq(5, 15, by=5)

pdx_flights_timeofday &amp;lt;- flights %&amp;gt;% 
                        filter(origin == &amp;quot;PDX&amp;quot;, !is.na(dep_time))%&amp;gt;%
                        select(dest, dep_time) %&amp;gt;%
                        mutate(time_of_day = case_when(dep_time &amp;gt;= 500 &amp;amp; dep_time &amp;lt; 1100 ~ &amp;quot;morning&amp;quot;,
                                                       dep_time &amp;gt;= 1100 &amp;amp; dep_time &amp;lt; 1900 ~ &amp;quot;evening&amp;quot;,
                                                       TRUE ~ &amp;quot;redeye&amp;quot;)) %&amp;gt;%
                        group_by(time_of_day, dest) %&amp;gt;%
                        count() %&amp;gt;%
                        group_by(time_of_day) %&amp;gt;%
                        arrange(desc(n)) %&amp;gt;%
                        top_n(5, n) %&amp;gt;%
                        mutate(dest_rank = case_when(row_number() %in% first_set ~ &amp;quot;dest_1&amp;quot;,
                                                     row_number() %in% second_set ~ &amp;quot;dest_2&amp;quot;,
                                                     row_number() %in% third_set ~ &amp;quot;dest_3&amp;quot;,
                                                     row_number() %in% fourth_set ~ &amp;quot;dest_4&amp;quot;,
                                                     row_number() %in% fifth_set ~ &amp;quot;dest_5&amp;quot;)) %&amp;gt;%
                        pivot_wider(names_from = c(time_of_day), 
                                    values_from = c(dest, n)) %&amp;gt;%
                        mutate(dest_rank = NULL) 

column_order &amp;lt;- c(&amp;quot;dest_morning&amp;quot;, &amp;quot;n_morning&amp;quot;, 
                  &amp;quot;dest_evening&amp;quot;, &amp;quot;n_evening&amp;quot;,
                  &amp;quot;dest_redeye&amp;quot;, &amp;quot;n_redeye&amp;quot;)

pdx_flights_timeofday &amp;lt;- pdx_flights_timeofday[, column_order]
  
pdx_flights_timeofday %&amp;gt;% gt() %&amp;gt;%
                       # tab_options(row.striping.background_color = &amp;quot;#f9f9f9&amp;quot;,
                       #             row.striping.include_table_body = TRUE,
                       #             row.striping.include_stub = TRUE) %&amp;gt;%
                       tab_header(title=&amp;quot;Most Frequent Destinations from PDX&amp;quot;,
                                  subtitle = &amp;quot;by Time of Day&amp;quot;) %&amp;gt;%
                       tab_spanner(label = &amp;quot;Morning&amp;quot;,
                                   columns = vars(dest_morning, n_morning)) %&amp;gt;%
                       tab_spanner(label = &amp;quot;Afternoon&amp;quot;,
                                  columns = vars(dest_evening, n_evening)) %&amp;gt;%
                       tab_spanner(label = &amp;quot;Redeye&amp;quot;,
                                  columns = vars(dest_redeye, n_redeye)) %&amp;gt;%
                       cols_label(dest_morning = &amp;quot;Destination&amp;quot;,
                                  n_morning = &amp;quot;Flights&amp;quot;,
                                  dest_evening = &amp;quot;Destination&amp;quot;,
                                  n_evening = &amp;quot;Flights&amp;quot;,
                                  dest_redeye = &amp;quot;Destination&amp;quot;,
                                  n_redeye = &amp;quot;Flights&amp;quot;) %&amp;gt;%
                        cols_align(align = &amp;quot;center&amp;quot;,
                                   columns = vars(dest_morning, dest_evening, dest_redeye)) %&amp;gt;%
                        summary_rows(columns = vars(n_morning, n_evening, n_redeye),
                                     fns = list(Total = ~sum(.)),
                                     formatter = fmt_number,
                                     decimals = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;style&gt;html {
  font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, Oxygen, Ubuntu, Cantarell, &#39;Helvetica Neue&#39;, &#39;Fira Sans&#39;, &#39;Droid Sans&#39;, Arial, sans-serif;
}

#xlzlbqmkrr .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#xlzlbqmkrr .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#xlzlbqmkrr .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#xlzlbqmkrr .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#xlzlbqmkrr .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#xlzlbqmkrr .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#xlzlbqmkrr .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#xlzlbqmkrr .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#xlzlbqmkrr .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#xlzlbqmkrr .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#xlzlbqmkrr .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#xlzlbqmkrr .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#xlzlbqmkrr .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#xlzlbqmkrr .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#xlzlbqmkrr .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#xlzlbqmkrr .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#xlzlbqmkrr .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#xlzlbqmkrr .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#xlzlbqmkrr .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#xlzlbqmkrr .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#xlzlbqmkrr .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#xlzlbqmkrr .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#xlzlbqmkrr .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#xlzlbqmkrr .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#xlzlbqmkrr .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#xlzlbqmkrr .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#xlzlbqmkrr .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#xlzlbqmkrr .gt_left {
  text-align: left;
}

#xlzlbqmkrr .gt_center {
  text-align: center;
}

#xlzlbqmkrr .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#xlzlbqmkrr .gt_font_normal {
  font-weight: normal;
}

#xlzlbqmkrr .gt_font_bold {
  font-weight: bold;
}

#xlzlbqmkrr .gt_font_italic {
  font-style: italic;
}

#xlzlbqmkrr .gt_super {
  font-size: 65%;
}

#xlzlbqmkrr .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
&lt;/style&gt;
&lt;div id=&#34;xlzlbqmkrr&#34; style=&#34;overflow-x:auto;overflow-y:auto;width:auto;height:auto;&#34;&gt;&lt;table class=&#34;gt_table&#34;&gt;
  &lt;thead class=&#34;gt_header&#34;&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;7&#34; class=&#34;gt_heading gt_title gt_font_normal&#34; style&gt;Most Frequent Destinations from PDX&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th colspan=&#34;7&#34; class=&#34;gt_heading gt_subtitle gt_font_normal gt_bottom_border&#34; style&gt;by Time of Day&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead class=&#34;gt_col_headings&#34;&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_left&#34; rowspan=&#34;2&#34; colspan=&#34;1&#34;&gt;&lt;/th&gt;
      &lt;th class=&#34;gt_center gt_columns_top_border gt_column_spanner_outer&#34; rowspan=&#34;1&#34; colspan=&#34;2&#34;&gt;
        &lt;span class=&#34;gt_column_spanner&#34;&gt;Morning&lt;/span&gt;
      &lt;/th&gt;
      &lt;th class=&#34;gt_center gt_columns_top_border gt_column_spanner_outer&#34; rowspan=&#34;1&#34; colspan=&#34;2&#34;&gt;
        &lt;span class=&#34;gt_column_spanner&#34;&gt;Afternoon&lt;/span&gt;
      &lt;/th&gt;
      &lt;th class=&#34;gt_center gt_columns_top_border gt_column_spanner_outer&#34; rowspan=&#34;1&#34; colspan=&#34;2&#34;&gt;
        &lt;span class=&#34;gt_column_spanner&#34;&gt;Redeye&lt;/span&gt;
      &lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Destination&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Flights&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Destination&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Flights&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Destination&lt;/th&gt;
      &lt;th class=&#34;gt_col_heading gt_columns_bottom_border gt_center&#34; rowspan=&#34;1&#34; colspan=&#34;1&#34;&gt;Flights&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class=&#34;gt_table_body&#34;&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left gt_stub&#34;&gt;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1921&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SFO&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;2495&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SFO&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;836&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left gt_stub&#34;&gt;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SFO&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1780&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;DEN&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1643&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;PHX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;587&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left gt_stub&#34;&gt;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;PHX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1454&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;PHX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1504&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SJC&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;572&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left gt_stub&#34;&gt;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;ORD&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1409&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;SLC&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1389&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;ANC&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;517&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_left gt_stub&#34;&gt;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1316&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAS&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;1308&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;LAX&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center&#34;&gt;426&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class=&#34;gt_row gt_stub gt_right gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;Total&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;&amp;mdash;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;7,880&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;&amp;mdash;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;8,339&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;&amp;mdash;&lt;/td&gt;
      &lt;td class=&#34;gt_row gt_center gt_grand_summary_row gt_first_grand_summary_row&#34;&gt;2,938&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
  
  
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;For this table, as opposed to the table in the second section, I wanted to encourage vertical scanning, to encourage the viewer to note the sequential ordering of the rows, i.e., the first row corresponds to the top flight for each timeframe. Fortunately, I didn’t have to change much from the default &lt;code&gt;gt&lt;/code&gt; settings, just tinker with a titles to get the columns arranged in a more harmonious way. I really wanted to find a way to visually separate each timeframe’s data, but had trouble finding how to add vertical bars to separate the groups…although that may have ended up a bit chaotic anyway. Spanning labels will have to do! I do feel like adding the row for the total flights helped a bit, as we can distinctively see three values, indicating three groups. I think this is a pretty cool analysis of the dataset, particularly because it shows rather in-depth information about the distribution of top flights for each time of day, but also the total flights. Redeyes are definitely less popular/frequent, unsurprisingly!&lt;/p&gt;
&lt;p&gt;As we can see, there are many interesting aspects of the &lt;code&gt;flights&lt;/code&gt; dataset that can be explored using nothing more than the humble table. With &lt;code&gt;gt&lt;/code&gt;, we can create elegant, easy-to-read tables even for rather complex data!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>All About the Population Pyramid!</title>
      <link>https://vigilant-golick-64a677.netlify.app/post/population-pyramid/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/post/population-pyramid/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;CS530_ARoten_GraphBrief1_files/figure-markdown_strict/unnamed-chunk-4-1.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A Population Pyramid, also known as an Age and Sex Pyramid is a
histogram-like visualization often used to provide a succinct, elegant
summary of differences in distribution of groups within a population.
The population is broken up by a two-level factor variable, with one on
each side of the visualization, and then the data is binned based on a
continuous variable. Although population pyramids typically use a factor
variable of sex (male and female), and a continuous variable of age, and
are often used to convey such information as a country’s fertility rate,
the visualization can be generalized to other situations, in which it
may be referred to as simply a “dual-sided histogram”. The type of
visualization is a handy way to enhance a typical histogram by splitting
it into two factor variables in order to facilitate comparison across
groups within a population, while still being able to make observations
about the population as a whole.&lt;/p&gt;
&lt;h2 id=&#34;how-to-read-a-population-pyramid-visualization&#34;&gt;How to Read a Population Pyramid Visualization&lt;/h2&gt;
&lt;p&gt;There are several useful takeaways that can be gleaned quickly and
easily using a population pyramid:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;How the overall distribution changes on the basis of &lt;em&gt;age&lt;/em&gt;&lt;/strong&gt;: To
get a sense of the age distribution for the overall population, one
can simply examine the shape of the plot/pyramid, focusing on how
&lt;em&gt;width changes from top to bottom&lt;/em&gt;. The wider the plot at any
particular height, the more individuals in the age group
corresponding to that position on the y-axis contribute to the
overall population. So, if the “base”/bottom is wide compared to the
rest of the plot, giving it a “pyramid”-like shape, the population
is comprised of mostly younger individuals. However, if the overall
“pyramid” is more rectangular, the age distribution is balanced. An
upside-down pyramid would indicate a generally older population, and
a “bulge” could indicate something like a baby boom around that
particular age bracket’s birth years.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;How the overall distribution differs based on &lt;em&gt;sex&lt;/em&gt;&lt;/strong&gt;: This is a
fairly simple piece of information to glean from this type of plot –
if the pyramid is &lt;em&gt;heavier on one side than the other&lt;/em&gt;, then the
population is skewed more heavily toward one particular sex than the
other.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;How the &lt;em&gt;sex&lt;/em&gt; distribution changes as a &lt;em&gt;function of age&lt;/em&gt;&lt;/strong&gt;: We
also can take into account both of the variables above and determine
whether the sex distribution differs based on the age of that
segment of the population. It’s difficult to think of an example
that is not tragic, but, say, a plot of the demographics of the U.S.
shortly after World War II may have more females than males in the
age bracket 18-25 years old, but would likely be balanced in age
brackets younger and older. In this case, the pyramid would be
&lt;em&gt;vertically asymmetric&lt;/em&gt;, with a &lt;em&gt;“notch”&lt;/em&gt; on the male side at that
age bracket. Examining the plot for these &lt;em&gt;notches&lt;/em&gt; is a quick,
simple way to determine whether the sex distribution differs for a
particular age group.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Finally, in traditional population pyramids which depict age/sex
distribution in a particular region, there are three shapes so commonly
seen that they are given specific labels: expanding, contracting, and
stationary, as shown below (graphic, as well as paraphrased information
on each shape from a paper by Daniel Staetsky, full citation can be
found in final section):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;pyramid_types.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A very triangular shape, with many more young representatives than
older, as in the &lt;strong&gt;expanding&lt;/strong&gt; pyramid, is indicative of a population
that is growing, along with high fertility/mortality rates. The
&lt;strong&gt;contracting&lt;/strong&gt; shape, where the pyramid is pinched at the base is
indicative of low fertility/mortality rates, corresponding to a
population with few young people, relative to the rest of the group.
Finally, the &lt;strong&gt;stationary&lt;/strong&gt; pyramid, which has a columnal shape, tends
to correspond to stable populations, with balanced, low fertility and
mortality rates.&lt;/p&gt;
&lt;p&gt;Disclosure: Given the wide spectrum of gender identities present in
modern society, I can absolutely understand how some may object to the
binary nature of the population pyramid. Although I, and most who employ
this type of visualization, specify the binary factor as biological
“sex”, not gender, issues still remain. After a quick search, it doesn’t
look like many have addressed this issue currently, but I would not be
surprised to see multi-way analyses in the future (population stars??)!&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;The data used to generate the examples at the top of this page comes
from the United States Consumer Product Safety Commission’s National
Electronic Injury Surveillance System dataset, which can be found at the
following link:
&lt;a href=&#34;https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data&#34;&gt;https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data&lt;/a&gt;&lt;/a&gt;
. This dataset is quite rich, containing data gathered from a large
number of emergency departments in the US. The overall dataset contains
demographic information, including sex, age, and ethnicity, as well as a
number of other interesting pieces of information including whether a
particular product was involved in the injury (as in the left plot
above, which includes all ER visits in the dataset from 2019 which
involved a trampoline), and whether drugs or alcohol were involved in
the injury. The dataset also includes for each datapoint/injury, a brief
narrative outlining the loose details of the incident. The website
contains a neat query system where the user can narrow down the dataset
by filtering for year, product involved, and other data characteristics.&lt;/p&gt;
&lt;h2 id=&#34;figure-specific-details&#34;&gt;Figure-Specific Details&lt;/h2&gt;
&lt;p&gt;I opted to use a population pyramid for a slighly atypical analysis in
the , that is, to examine the demographics of patients who visited a
number of U.S. emergency rooms in 2019, using the dataset described
above. I chose to narrow the dataset to two types of emergency room
incidents, to depict two very different-looking population pyramids: the
left plot shows the distribution of patients who visited the ER due to
trampoline-related accidents, and the right plot shows the same of
patients who visited the ER due to incidents involving the use of
alcohol.&lt;/p&gt;
&lt;p&gt;I’ll use the general framework for interpreting a population pyramid
described above to discuss the information I gleaned from these plots,
first analyzing the plot on the left, then the plot on the right.&lt;/p&gt;
&lt;h3 id=&#34;trampoline-based-injuries&#34;&gt;Trampoline-Based Injuries&lt;/h3&gt;
&lt;p&gt;As stated, this plot shows a breakdown of the age and sex
characteristics of the group of individuals who visited the emergency
room due to trampoline accidents in 2019. Prior to generating the plot,
I hypothesized that the shape would be heavy at the base, and thinner on
the top, as children are typical trampoline users, and I recall from my
daredevil youth that I much preferred playing on a trampoline without a
protective net. Though as an adult, I still struggle to ignore the siren
song of the trampoline, I tend to be more careful than when I was a
child. Stereotypes might lead some to believe that male children are
more prone to taking trampoline-related risks, but I knew many a
reckless young female when I was growing up, so I hypothesized a
symmetric pyramid.&lt;/p&gt;
&lt;p&gt;Indeed, this is what the plot shows – a &lt;em&gt;very&lt;/em&gt; heavy base, with a peak
around 9-10 years old. Around the teenage years, these injuries drop off
significantly, although not completely, perhaps in part due to some in
the 25-40 year old age group having young children, and being tempted by
their child’s trampoline. However, once we hit the mid-40’s, there are
very few representatives from that cohort and older in this population.
Additionally, the plot is quite &lt;em&gt;symmetric&lt;/em&gt; – males and females are
more-or-less equally represented in this population. There doesn’t
appear to be an interaction of age and sex, as there are no bulges or
notches present on one side but not the other.&lt;/p&gt;
&lt;h3 id=&#34;accidents-involving-alcohol&#34;&gt;Accidents Involving Alcohol&lt;/h3&gt;
&lt;p&gt;A slightly more sobering (sorry!) analysis is on the right – a
population pyramid showing the age/sex distribution amongst ER visits
resulting from alcohol-related injuries. In this case, I did hypothesize
a difference between sexes, with males making up a somewhat larger
proportion of the population, though still a fair few females. I also
predicted a pear-shaped pyramid, with very few representatives from the
0-20 year old cohort, the bulk of patients in the 20-30 year old range,
and a consistent taper down as age increased.&lt;/p&gt;
&lt;p&gt;I was somewhat surprised by the shape of the resulting plot. Although
I’d anticipated a plot that was &lt;em&gt;heavier on the male side than the
female side&lt;/em&gt;, I hadn’t expected the difference to be so dramatic. Almost
across the board, each male age cohort has about double (if not more)
members than the corresponding female cohort. I was also surprised to
see bimodal distributions on both sides, with a bulge from about the
mid-teens through around 35, but then an even larger bulge in the older
years, peaking around the early-to-mid sixties. Folks getting wild in
their retirement years! Though females are represented less in the
overall population distribution, these characteristics are still present
in that sub-population’s distribution.&lt;/p&gt;
&lt;p&gt;I could see analyses like these being useful for target specific groups
to recieve safety training on a particular product, deciding who to
design flyers for, which, say, encourage moderation and safety when
consuming alcohol, or to determine suggested age ranges for certain play
equipment.&lt;/p&gt;
&lt;h2 id=&#34;presentation-tips&#34;&gt;Presentation Tips&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Color:&lt;/strong&gt; Typically, this type of visualization uses color in a simple
fashion, either using a uniform color and annotating each side with the
appropriate label, or selecting two distinct colors to distinguish
between one side and the other. Since a population pyramid generally
plots the distribution of males versus females, we often see plots that
select pink for the female distribution and blue for the male
distribution. However, this is a bit of an anachronism in today’s
society, as these colors carry the weight of long-term stereotypical
gender associations. Some argue that choosing these colors allows for
speedy interpretation of the figure, however, if a reader has so little
time or mental energy that scanning a legend is unmanagable, then, well,
perhaps they should skip looking at the figure altogether.
Interestingly, it has been suggested that simply flipping the colors
around can be problematic, as it can lead to confusion due to the
aforementioned speedy interpretation of those particular colors in a
figure.&lt;/p&gt;
&lt;p&gt;So, I chose to create a graph with different colors altogether, inspired
by the color choices in the Telegraph; green for males, and purple for
females. A discussion of the motivation behind this choice, as well as
more detailed arguments against the selection of blue/pink to
distinguish male/female populations can be found at the following link:
&lt;a href=&#34;https://blog.datawrapper.de/gendercolor/&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://blog.datawrapper.de/gendercolor/&#34;&gt;https://blog.datawrapper.de/gendercolor/&lt;/a&gt;&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;Although some may consider it an attractive or interesting design detail
to apply a color gratient based on age, this is not a common choice. Not
only is it unnecessary to code this using color, since the axis makes
the age range quite clear, it could also distract readers.&lt;/p&gt;
&lt;p&gt;Finally, avoid this color choice for this type of visualization at all
costs! (But please do use this very attractive 70’s-inspired rainbow
palette for your artistic projects!)&lt;/p&gt;
&lt;a href=&#34;https://www.geo41.com/population-structure&#34;&gt; 
&lt;img src=&#34;bad_color.png&#34; style=&#34;display: block; margin: auto;&#34;/&gt;
&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;Composition:&lt;/strong&gt; Since these plots are fairly straight-forward, there
are only a few small details to keep in mind regarding composition. The
first is that even if the most populous bin in on one side is less than
the most populous bin on the other, the x-axis should range from [-n,
n], with n corresponding to the most populous bin overall. Although
this is a small detail, this places the line dividing the sex/two-factor
distributions directly in the middle of the plot, which can aid in
accurate comparison of one sub-population versus the other. Also, in my
opinion, it is much more visually harmonious.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;CS530_ARoten_GraphBrief1_files/figure-markdown_strict/unnamed-chunk-5-1.png&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Annotation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Population Pyramid is a useful visualization in no small part
because of the rich possibilities of interpretation without the need for
excessive labeling or annotation. However, if a particular feature of
the shape of the plot corresponds to, say, a cultural event that is
relevant to the context of the figure, it would be acceptable to add a
small annotation to the plot, indicating the events related to the
feature of the plot. As with all graph annotation, it is better to keep
it minimal and clean. Below is an example of a well-annotated population
pyramid (although perhaps with a bit much going on, I would personally
keep it to one or two annotations):&lt;/p&gt;
&lt;a href=&#34;http://japanjapan.blogspot.com/2010/06/japans-population-structure.html&#34;&gt; 
&lt;img src=&#34;good_annotation.png&#34; style=&#34;display: block; margin: auto;&#34;/&gt;
&lt;/a&gt;
&lt;p&gt;Although the annotations/labels add a fair bit of busyness to the
figure, the story behind the plot is enriched with the additional
details. Note that in addition to the annotations, the figure overlays
the outline of a population pyramid from an earlier date on top of the
more recent pyramid. This also allows additional temporal information to
the figure’s story, which I find to be quite effective.&lt;/p&gt;
&lt;p&gt;In contrast, here is a poorly annotated population pyramid:&lt;/p&gt;
&lt;a href=&#34;https://pt.slideshare.net/JonathanHall66/analysing-populationpyramids/6?smtNoRedir=1&#34;&gt; 
&lt;img src=&#34;bad_annotation.png&#34; style=&#34;display: block; margin: auto;&#34;/&gt;
&lt;/a&gt;
&lt;p&gt;First of all…that font! But, that is not relevant to the discussion of
the pyramid itself. In this case, although there is certainly
information added through the annotations, the positioning and quantity
of labels distracts from the overall impact of the figure. This quantity
of information would be better suited to a narrative setting, alongside
the figure, perhaps with numerical annotations indicating the feature of
the plot that corresponds with the additional contextual information.
However, the lines indicating the positions on the plat that correspond
to each annotation are confusing, in that they point directly to one or
the other side of the pyramid. This configuration could come across to
the viewer as if only one of the sub-populations corresponds to the
information in the annotation, e.g. the middle annotation on the
right-hand side appears to be referring only to the female side of the
pyramid, however, certainly females are not the only humans who will
age!&lt;/p&gt;
&lt;h2 id=&#34;methods&#34;&gt;Methods&lt;/h2&gt;
&lt;p&gt;Below is the code used to create one of the population pyramids, broken
up into a chunk that shows the data wrangling process, and then one
showing the plot generation, including the &lt;code&gt;ggarrange()&lt;/code&gt; call that was
used to combine the two plots.&lt;/p&gt;
&lt;h3 id=&#34;data-wrangling&#34;&gt;Data Wrangling&lt;/h3&gt;
&lt;p&gt;The data wrangling process was pretty straight-forward after downloading
the data from the link provided in the data section, specifically
downloading and working with the entire dataset from 2019. The .xlsx
file consists of a row corresponding to each emergency room visit, and
the columns to each piece of information related to that incident, so I
simply had to narrow down the dataset to only include rows where the
column &lt;code&gt;alcohol_involved&lt;/code&gt; was equal to one. I also filtered out rows
with age values higher than 100, as there were some instances where the
age column contained a code that was not the actual age in years. I also
filtered out rows where the patient’s sex was unknown.&lt;/p&gt;
&lt;p&gt;Since the dataset originally included column names with spaces, a
configuration that does not play well with R code, I used the handy
&lt;code&gt;janitor::clean_names()&lt;/code&gt; function to convert the column names into
R-friendly strings. Finally, I replaced the 1/2 indicators with
“Male”/“Female”, primarily as a hacky way of making the plot’s legend
more attractive, although this could have been done directly during the
plotting phase. Finally, I narrowed the dataset down to just the sex and
age columns, which is all that was needed for the population pyramids.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alcohol_data &amp;lt;- read_excel(&amp;quot;neiss2019.xlsx&amp;quot;) %&amp;gt;%
                 janitor::clean_names() %&amp;gt;%
                 filter(alcohol_involved == 1, sex != 0, age &amp;lt; 100) %&amp;gt;%
                 mutate(sex = ifelse(sex == 1, &amp;quot;Male&amp;quot;, &amp;quot;Female&amp;quot;)) %&amp;gt;%
                 select(sex, age)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;plotting&#34;&gt;Plotting&lt;/h3&gt;
&lt;p&gt;The plots I created were adapted from code a couple of handy tutorials;
the first two links in the citation section below. The two plots were
then set up to display side-by-side using &lt;code&gt;ggarrange()&lt;/code&gt;. Each function
call is annotated in the R chunk below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;booze_pyramid &amp;lt;- ggplot(data = alcohol_data, aes(x = age, fill = sex)) +     # Basic ggplot call, 
                                                                             # specifying age as the 
                                                                             # x-values and the 
                                                                             # fill value to be  
                                                                             # selected based on the 
                                                                             # sex value. 
  
                 geom_histogram(data = subset(alcohol_data, sex == &amp;quot;Male&amp;quot;),  # Creating the histogram 
                                     bins = 35, color = &amp;quot;lightgrey&amp;quot;) +       # for the male data.
  
                 geom_histogram(data = subset(alcohol_data, sex == &amp;quot;Female&amp;quot;),# Creating the histogram for
                               mapping = aes(y = - ..count.. ),              # the female data. Note that
                               position = &amp;quot;identity&amp;quot;,                        # the count/y is mapped to
                               bins = 35, color = &amp;quot;lightgrey&amp;quot;) +             # negative values, to flip
                                                                             # the bars.
  
                 scale_y_continuous(limits = c(-350, 350), labels = abs) +   # Manually setting the axis
                 scale_x_continuous(limits = c(0, 100)) +                    # ranges.
  
                 coord_flip() +                                              # Flipping the x/y axes.
  
                 ggtitle(&amp;quot;Involving Alcohol-Use&amp;quot;) +                          # Tweaking the title and 
                 ylab(&amp;quot;Count&amp;quot;) +                                             # other details.
                 theme_minimal() +
                 theme(plot.title = element_text(size = 10, hjust = 0.5)) +
                 scale_fill_manual(values = c(&amp;quot;#80337c&amp;quot;, &amp;quot;#338057&amp;quot;)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;ggarrange()&lt;/code&gt; call is included below, as this is a handy function to
include several individual plots in a single overall figure.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pyramid_two &amp;lt;- ggarrange(trampoline_pyramid, booze_pyramid, heights = c(2, 2), # Call to ggarrange, 
                    ncol = 2, nrow = 1, common.legend = TRUE, align = &#39;v&#39;,     # passing in both plot
                                                                               # objects and setting
                    legend = &amp;quot;right&amp;quot;) %&amp;gt;%                                      # display params.
                                                                               
                                                                               # Adding &amp;quot;overall&amp;quot; fig 
                                                                               # title.
               annotate_figure(top = text_grob(&amp;quot;Accidents Resulting in \nEmergency Room Visits in 2019\n &amp;quot;, 
                                               face = &amp;quot;bold&amp;quot;, size = 16))

## Warning: Removed 2 rows containing missing values (geom_bar).

## Warning: Removed 2 rows containing missing values (geom_bar).

## Warning: Removed 2 rows containing missing values (geom_bar).

## Warning: Removed 2 rows containing missing values (geom_bar).

## Warning: Removed 2 rows containing missing values (geom_bar).

## Warning: Removed 2 rows containing missing values (geom_bar).
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;additional-citations&#34;&gt;Additional Citations&lt;/h3&gt;
&lt;p&gt;Staetsky, Daniel. (2015). Strictly Orthodox Rising: what the demography
of British Jews tells us about the future of the community.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://rpubs.com/walkerke/pyramids_ggplot2&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://rpubs.com/walkerke/pyramids_ggplot2&#34;&gt;https://rpubs.com/walkerke/pyramids_ggplot2&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/14680075/simpler-population-pyramid-in-ggplot2&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://stackoverflow.com/questions/14680075/simpler-population-pyramid-in-ggplot2&#34;&gt;https://stackoverflow.com/questions/14680075/simpler-population-pyramid-in-ggplot2&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data&#34;&gt;https://www.cpsc.gov/Research--Statistics/NEISS-Injury-Data&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.whiteplainspublicschools.org/cms/lib/NY01000029/Centricity/Domain/353/Population%20Pyramids%20Geography.pdf&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://www.whiteplainspublicschools.org/cms/lib/NY01000029/Centricity/Domain/353/Population%20Pyramids%20Geography.pdf&#34;&gt;https://www.whiteplainspublicschools.org/cms/lib/NY01000029/Centricity/Domain/353/Population%20Pyramids%20Geography.pdf&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://populationeducation.org/what-are-different-types-population-pyramids/&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://populationeducation.org/what-are-different-types-population-pyramids/&#34;&gt;https://populationeducation.org/what-are-different-types-population-pyramids/&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0&#34;&gt;https://docs.google.com/spreadsheets/d/1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk/edit#gid=0&lt;/a&gt;&lt;/a&gt;
&lt;a href=&#34;https://datavizcatalogue.com&#34; class=&#34;uri&#34;&gt;&lt;a href=&#34;https://datavizcatalogue.com&#34;&gt;https://datavizcatalogue.com&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://vigilant-golick-64a677.netlify.app/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://vigilant-golick-64a677.netlify.app/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>https://vigilant-golick-64a677.netlify.app/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://vigilant-golick-64a677.netlify.app/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
